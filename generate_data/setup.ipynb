{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBhF3VpGuIt2"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "id": "GMLtO9WlbCHH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting inflect\n",
      "  Using cached inflect-7.0.0-py3-none-any.whl (34 kB)\n",
      "Collecting pydantic>=1.9.1\n",
      "  Using cached pydantic-2.3.0-py3-none-any.whl (374 kB)\n",
      "Requirement already satisfied: typing-extensions in /Users/jerome/anaconda3/envs/research/lib/python3.11/site-packages (from inflect) (4.5.0)\n",
      "Collecting annotated-types>=0.4.0\n",
      "  Using cached annotated_types-0.5.0-py3-none-any.whl (11 kB)\n",
      "Collecting pydantic-core==2.6.3\n",
      "  Downloading pydantic_core-2.6.3-cp311-cp311-macosx_11_0_arm64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hCollecting typing-extensions\n",
      "  Using cached typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
      "Installing collected packages: typing-extensions, annotated-types, pydantic-core, pydantic, inflect\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.5.0\n",
      "    Uninstalling typing_extensions-4.5.0:\n",
      "      Successfully uninstalled typing_extensions-4.5.0\n",
      "Successfully installed annotated-types-0.5.0 inflect-7.0.0 pydantic-2.3.0 pydantic-core-2.6.3 typing-extensions-4.8.0\n",
      "Requirement already satisfied: kaleido in /Users/jerome/anaconda3/envs/research/lib/python3.11/site-packages (0.2.1)\n",
      "Requirement already satisfied: openai in /Users/jerome/anaconda3/envs/research/lib/python3.11/site-packages (0.27.8)\n",
      "Requirement already satisfied: requests>=2.20 in /Users/jerome/anaconda3/envs/research/lib/python3.11/site-packages (from openai) (2.29.0)\n",
      "Requirement already satisfied: tqdm in /Users/jerome/anaconda3/envs/research/lib/python3.11/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in /Users/jerome/anaconda3/envs/research/lib/python3.11/site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jerome/anaconda3/envs/research/lib/python3.11/site-packages (from requests>=2.20->openai) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jerome/anaconda3/envs/research/lib/python3.11/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/jerome/anaconda3/envs/research/lib/python3.11/site-packages (from requests>=2.20->openai) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jerome/anaconda3/envs/research/lib/python3.11/site-packages (from requests>=2.20->openai) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/jerome/anaconda3/envs/research/lib/python3.11/site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/jerome/anaconda3/envs/research/lib/python3.11/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/jerome/anaconda3/envs/research/lib/python3.11/site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/jerome/anaconda3/envs/research/lib/python3.11/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/jerome/anaconda3/envs/research/lib/python3.11/site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/jerome/anaconda3/envs/research/lib/python3.11/site-packages (from aiohttp->openai) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install inflect\n",
    "!pip install -U kaleido\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Fhq8vZCEnWkF"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import inflect\n",
    "import os\n",
    "import json\n",
    "import kaleido\n",
    "import tqdm\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple, Dict, Callable\n",
    "from abc import ABC, abstractmethod\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "\n",
    "ie = inflect.engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fZAKrJYApSHH"
   },
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "KYP9fN7EoTRF"
   },
   "outputs": [],
   "source": [
    "def save_map(m: object, filename: str) -> None:\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(m, f)\n",
    "\n",
    "def load_map(filename: str) -> None:\n",
    "    with open(filename, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def get_similarity(a: str, b: str, sim_map: dict) -> float:\n",
    "    if a in sim_map and b in sim_map[a]:\n",
    "        return sim_map[a][b]\n",
    "    elif b in sim_map and a in sim_map[b]:\n",
    "        return sim_map[b][a]\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "def scm(premises: list, c: str, all_c: list, sim_map: dict, specific: bool = True, alpha: float = 0.5) -> float:\n",
    "\n",
    "    if not specific:\n",
    "        conclusion_categories_1 = all_c\n",
    "    else:\n",
    "        conclusion_categories_1 = [c]\n",
    "    a = np.mean([\n",
    "        np.max([\n",
    "            get_similarity(p, c_cat, sim_map)\n",
    "            for p in premises if p\n",
    "        ])\n",
    "        for c_cat in conclusion_categories_1\n",
    "    ])\n",
    "\n",
    "    # calculate b\n",
    "    conclusion_categories_2 = all_c\n",
    "    b = np.mean([\n",
    "        np.max([\n",
    "            get_similarity(p, c_cat, sim_map)\n",
    "            for p in premises if p\n",
    "        ])\n",
    "        for c_cat in conclusion_categories_2\n",
    "    ])\n",
    "\n",
    "    return alpha*a + (1-alpha)*b\n",
    "\n",
    "def pluralise_category(category):\n",
    "    if category not in (\"Mammals\", \"Vehicles\", \"Birds\", \"Animals\", \"Things\", \"Objects\"):\n",
    "        return ie.plural(category).lower().capitalize()\n",
    "    else:\n",
    "        return \"All \" + category.lower()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DnRELFQIpUdQ"
   },
   "source": [
    "#### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "mQQciqqRocIq"
   },
   "outputs": [],
   "source": [
    "ROOT = \"../data/setup\"\n",
    "\n",
    "RAW_DATA = f\"{ROOT}/raw\"\n",
    "PROCESSED_DATA = f\"{ROOT}/processed\"\n",
    "\n",
    "NUM_PARTICIPANTS_PER_TRIAL = 10\n",
    "\n",
    "NUM_SINGLE_PREMISE_ARGS_PER_BATCH = 24\n",
    "\n",
    "EXPERIMENT_1_CONTROLS = {\n",
    "    ((('Hippos',), 'Chickens'), (('Hippos',), 'Rhinos')): True,\n",
    "    ((('Lions',), 'Penguins'), (('Lions',), 'Tigers')): True,\n",
    "    ((('Mopeds',), 'Motorbikes'), (('Mopeds',), 'Screwdrivers')): False,\n",
    "    ((('Robins',), 'Gorillas'), (('Robins',), 'Sparrows')): True\n",
    "}\n",
    "EXPERIMENT_2_SINGLE_PREMISE_CONTROLS = {\n",
    "  \"General\": {\n",
    "    \"Mammals\": [(\"All animals\", \"All mammals\"), (\"All living things\", \"All mammals\"), (\"All plants and animals\", \"All mammals\"), (\"All things that are alive\", \"All mammals\")],\n",
    "    \"Birds\": [(\"All animals\", \"All birds\"), (\"All living things\", \"All birds\"), (\"All plants and animals\", \"All birds\"), (\"All things that are alive\", \"All birds\")],\n",
    "    \"Vehicles\": [(\"All man-made things\", \"All vehicles\"), (\"All things\", \"All vehicles\"), (\"All things that can move\", \"All vehicles\"), (\"All things that can carry people\", \"All vehicles\")],\n",
    "  },\n",
    "  \"Specific\": {\n",
    "    \"Mammals\": [(\"Dogs\", \"Canines\"), (\"Cats\", \"Felines\"), (\"Horses\", \"Ponies\"), (\"Cows\", \"Cattle\")],\n",
    "    \"Birds\": [(\"Crows\", \"Ravens\"), (\"Hawks\", \"Falcons\"), (\"Pigeons\", \"Doves\"), (\"Finches\", \"Sparrows\")],\n",
    "    \"Vehicles\": [(\"Trucks\", \"Lorries\"), (\"Taxis\", \"Cabs\"), (\"Mopeds\", \"Scooters\"), (\"Trains\", \"Locomotives\")],\n",
    "  },\n",
    "}\n",
    "EXPERIMENT_2_MULTI_PREMISE_CONTROLS = {\n",
    "    \"General\": {\n",
    "        \"Mammals\": [[\"All animals\", \"All organisms\"], \"All mammals\"],\n",
    "        \"Birds\": [[\"All animals\", \"All organisms\"], \"All birds\"],\n",
    "        \"Vehicles\": [[\"All transport\", \"All moving things\"], \"All vehicles\"],\n",
    "    },\n",
    "    \"Specific\": {\n",
    "      \"Mammals\": [[\"Canines\", \"Puppies\"], \"Dogs\"],\n",
    "      \"Birds\": [[\"Hawks\", \"Eagles\"], \"Falcons\"],\n",
    "      \"Vehicles\": [[\"Locomotives\", \"Trams\"], \"Trains\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "EXPERIMENT_2_TRAINING_TRIALS = {\n",
    "    \"General\": {\n",
    "        \"single_premise\": [\"training_1_0\", \"training_1_1\",],\n",
    "        \"multi_premise\": [\"training_2_0\", \"training_2_1\",],\n",
    "    },\n",
    "    \"Specific\": {\n",
    "        \"single_premise\": [\"training_3_0\", \"training_3_1\",],\n",
    "        \"multi_premise\": [\"training_4_0\", \"training_4_1\",],\n",
    "    }\n",
    "}\n",
    "\n",
    "OSHERSON_CATEGORIES = {\n",
    "      \"Mammals\": [\"Hippos\", \"Hamsters\", \"Rhinos\", \"Lions\", \"Giraffes\", \"Rabbits\", \"Tigers\", \"Foxes\", \"Pigs\", \"Wolves\", \"Gorillas\", \"Mice\", \"Bats\", \"Horses\", \"Cows\", \"Chimps\", \"Dolphins\", \"Squirrels\", \"Seals\"],\n",
    "      \"Birds\": [\"Robins\", \"Penguins\", \"Bluejays\", \"Sparrows\", \"Hawks\", \"Falcons\", \"Geese\", \"Crows\", \"Peacocks\", \"Ostriches\"],\n",
    "    }\n",
    "OSHERSON_E2_CATEGORIES = [\"horse\", \"cow\", \"chimp\", \"gorilla\", \"mouse\", \"squirrel\", \"dolphin\", \"seal\", \"elephant\", \"rhino\"]\n",
    "\n",
    "OSHERSON_PHENOMENON_NUMBERS = {\n",
    "    1: \"Premise-conclusion Similarity\",\n",
    "    2: \"Premise Typicality\",\n",
    "    3: \"Conclusion Specificity\",\n",
    "    4: \"Premise Monotonicity (General)\",\n",
    "    5: \"Premise Monotonicity (Specific)\",\n",
    "    6: \"Premise Diversity (General)\",\n",
    "    7: \"Premise Diversity (Specific)\",\n",
    "    8: \"Nonmonotonicity (General)\",\n",
    "    9: \"Nonmonotonicity (Specific)\",\n",
    "    10: \"Premise-conclusion Asymmetry\",\n",
    "    11: \"Inclusion Fallacy\",\n",
    "}\n",
    "\n",
    "PHENOMENON_ORDER = {\n",
    "    \"Similarity\": 1,\n",
    "    \"Typicality\": 2,\n",
    "    \"Specificity\": 3,\n",
    "    \"Monotonicity (General)\": 4,\n",
    "    \"Monotonicity (Specific)\": 5,\n",
    "    \"Diversity (General)\": 6,\n",
    "    \"Diversity (Specific)\": 7,\n",
    "    \"Nonmonotonicity (General)\": 8,\n",
    "    \"Nonmonotonicity (Specific)\": 9,\n",
    "    \"Asymmetry\": 10,\n",
    "    \"Inclusion Fallacy\": 11,\n",
    "}\n",
    "\n",
    "PHENOMENON_TYPE = {\n",
    "    \"Similarity\": \"Specific\",\n",
    "    \"Typicality\": \"General\",\n",
    "    \"Specificity\": \"General\",\n",
    "    \"Monotonicity (General)\": \"General\",\n",
    "    \"Monotonicity (Specific)\": \"Specific\",\n",
    "    \"Diversity (General)\": \"General\",\n",
    "    \"Diversity (Specific)\": \"Specific\",\n",
    "    \"Nonmonotonicity (General)\": \"Mixed\",\n",
    "    \"Nonmonotonicity (Specific)\": \"Mixed\",\n",
    "    \"Asymmetry\": \"Specific\",\n",
    "    \"Inclusion Fallacy\": \"General\",\n",
    "}\n",
    "\n",
    "DOMAINS = {\n",
    "    \"Vehicles\": \"all vehicle\",\n",
    "    \"Birds\": \"all bird\",\n",
    "    \"Mammals\": \"all mammal\",\n",
    "    \"Things\": \"all thing\",\n",
    "    \"Animals\": \"all animal\"\n",
    "}\n",
    "\n",
    "DOMAIN_PARENTS = {\n",
    "    \"Mammals\": \"living things\",\n",
    "    \"Birds\": \"living things\",\n",
    "    \"Vehicles\": \"objects\",\n",
    "    \"Reptiles\": \"living things\",\n",
    "    \"Insects\": \"living things\",\n",
    "    \"Fruits\": \"foods\",\n",
    "}\n",
    "\n",
    "MAIN_DOMAINS = [\"Mammals\", \"Birds\", \"Vehicles\"]\n",
    "DD_DOMAINS = [\"Mammals\", \"Birds\", \"Vehicles\", \"Insects\", \"Reptiles\", \"Tools\", \"Professions\", \"Sports\", \"KitchenUtensils\", \"Vegetables\", \"Clothing\", \"MusicalInstruments\", \"Weapons\", \"Fruit\", \"Fish\"]\n",
    "NUMBERED_DOMAINS = {\"Mammals\": 0, \"Birds\": 1, \"Vehicles\": 2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZvaMzW2pXIh"
   },
   "source": [
    "# One time setup\n",
    "## Clean DeDeyne data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "TadEqlJHpHTh"
   },
   "outputs": [],
   "source": [
    "# Rename certain dedeyne categories into more common forms\n",
    "# CATEGORY_RENAME = {\"dromedary\": \"camel\", \"rhinocerous\": \"rhino\", \"hippopotamus\": \"hippo\", \"parakeet\": \"parrot\", \"cuckoo\": \"\", \"pheasant\": \"\", \"chickadee\": \"\", \"bison\": \"\", \"file\": \"\", \"caiman\": \"\", \"blindworm\": \"\", \"boa\": \"boa constrictor\", \"bat\": \"\"}\n",
    "CATEGORY_RENAME = {\"dromedary\": \"camel\", \"rhinocerous\": \"rhino\", \"hippopotamus\": \"hippo\", \"parakeet\": \"parrot\", \"boa\": \"boa constrictor\", \"cuckoo\": \"\", \"pheasant\": \"\", \"chickadee\": \"\", \"bison\": \"\", \"caiman\": \"\", \"blindworm\": \"\",}\n",
    "\n",
    "# Category rows for each dedeyene dataframe\n",
    "DD_CATEGORIES = {\n",
    "    \"Vehicles\": [\"car\", \"boat\", \"moped\", \"motorbike\", \"bus\", \"truck\", \"van\", \"caravan\", \"submarine\", \"bicycle\", \"go-cart\", \"helicopter\", \"hovercraft\", \"jeep\", \"cart\", \"carriage\", \"hot air balloon\", \"subway train\", \"motorbike\", \"rocket\", \"skateboard\", \"sled\", \"kick scooter\", \"taxi\", \"tractor\", \"tram\", \"train\", \"airplane\", \"truck\", \"zeppelin\"],\n",
    "    \"Birds\": [\"eagle\", \"dove\", \"duck\", \"magpie\", \"pheasant\", \"vulture\", \"rooster\", \"turkey\", \"canary\", \"chicken\", \"cuckoo\", \"crow\", \"chickadee\", \"seagull\", \"blackbird\", \"sparrow\", \"stork\", \"parrot\", \"parakeet\", \"peacock\", \"pelican\", \"penguin\", \"heron\", \"robin\", \"woodpecker\", \"ostrich\", \"owl\", \"falcon\", \"swan\", \"swallow\"],\n",
    "    \"Mammals\": [\"monkey\", \"beaver\", \"bison\", \"camel\", \"squirrel\", \"hedgehog\", \"donkey\", \"giraffe\", \"hamster\", \"deer\", \"dog\", \"polar bear\", \"kangaroo\", \"cat\", \"cow\", \"rabbit\", \"llama\", \"lion\", \"mouse\", \"rhinocerous\", \"hippopotamus\", \"elephant\", \"horse\", \"sheep\", \"tiger\", \"pig\", \"bat\", \"fox\", \"wolf\", \"zebra\"],\n",
    "    \"Insects\": [\"bee\", \"leech\", \"horsefly\", \"centipede\", \"fruit fly\", \"bumblebee\", \"cockroach\", \"beetle\", \"cricket\", \"dragonfly\", \"ladybug\", \"louse\", \"cockchafer\", \"ant\", \"moth\", \"mosquito\", \"earwig\", \"wood louse\", \"caterpillar\", \"spider\", \"grasshopper\", \"fly\", \"butterfly\", \"flee\", \"wasp\", \"worm\"],\n",
    "    \"Reptiles\": [\"viper\", \"alligator\", \"boa\", \"cobra\", \"dinosaur\", \"gecko\", \"lizard\", \"blindworm\", \"caiman\", \"chameleon\", \"frog\", \"crocodile\", \"iguana\", \"toad\", \"python\", \"salamander\", \"tortoise\", \"snake\", \"monitor lizard\", \"turtle\"],\n",
    "    \"Tools\": [\"anvil\", \"chisel\", \"axe\", \"drill\", \"crowbar\", \"screw wrench\", \"lawn mower\", \"hammer\", \"spanner\", \"pickaxe\", \"crowbar\", 'wheelbarrow', \"knife\", \"wrench\", \"oil can\", \"filling knife\", \"plough\", \"plane\", \"shovel\", \"screwdriver\", \"grinding disc\", \"nail\", \"wire brush\", \"vacuum cleaner\", \"tongs\", \"rope\", \"paint brush\", \"file\", \"level\", \"saw\"]\n",
    "}\n",
    "\n",
    "# Pluralised version of the above\n",
    "DD_CATEGORIES_PLURAL = {k: [ie.plural(x).capitalize() for x in v] for k,v in DD_CATEGORIES.items()}\n",
    "\n",
    "# Stuff to fix the inconsistencies in the DD datasets\n",
    "@dataclass\n",
    "class MatrixTranslationMixup:\n",
    "    \"\"\"Some of the De Deyne csv's have incorrectly labelled Dutch and English columns and rows that need to be manually coded for correction.\"\"\"\n",
    "    columns_are_switched: bool\n",
    "    rows_are_switched: bool\n",
    "        \n",
    "mixups = {\n",
    "    \"Birds\": MatrixTranslationMixup(False, True),\n",
    "    \"Clothing\": MatrixTranslationMixup(False, True),\n",
    "    \"Fish\": MatrixTranslationMixup(False, True),\n",
    "    \"Fruit\": MatrixTranslationMixup(True,False),\n",
    "    \"Insects\": MatrixTranslationMixup(False, False),\n",
    "    \"KitchenUtensils\": MatrixTranslationMixup(False, False),\n",
    "    \"Mammals\": MatrixTranslationMixup(False, False),\n",
    "    \"MusicalInstruments\": MatrixTranslationMixup(False, True),\n",
    "    \"Professions\": MatrixTranslationMixup(True, False),\n",
    "    \"Reptiles\": MatrixTranslationMixup(False, False),\n",
    "    \"Sports\": MatrixTranslationMixup(True, False),\n",
    "    \"Vegetables\": MatrixTranslationMixup(True, False),\n",
    "    \"Vehicles\": MatrixTranslationMixup(False, True),\n",
    "    \"Weapons\": MatrixTranslationMixup(False, False),\n",
    "    \"Tools\": MatrixTranslationMixup(False, False),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "J_Wnoa8wpawB"
   },
   "outputs": [],
   "source": [
    "def process_category(category: str) -> str:\n",
    "    o = \"\"\n",
    "    for c in category.strip():\n",
    "        if c.isalpha() or c == \" \":\n",
    "            o += c\n",
    "    return o\n",
    "\n",
    "\n",
    "def generate_similarity_typicality_dataframes(balance_osherson: bool = False) -> Tuple[Dict[str, pd.DataFrame], Dict[str, pd.DataFrame]]:\n",
    "\n",
    "    similarity_dataframes, typicality_dataframes = {}, {}\n",
    "\n",
    "    for domain in DD_DOMAINS:\n",
    "\n",
    "        # Read raw typicality dataframe\n",
    "        tdf = pd.read_csv(f\"{RAW_DATA}/de_deyne_typicality/exemplarTypicalityRatings-{domain.lower()}.CSV\", index_col=0, encoding = \"ISO-8859-1\").rename({\"Unnamed: 1\":\"category\", \"mean\": \"mean_typicality\"}, axis=1)[[\"category\", \"mean_typicality\"]].reset_index(drop=True).dropna()\n",
    "        tdf[\"category\"] = [process_category(c) for c in tdf[\"category\"]]\n",
    "        if domain in DD_CATEGORIES:\n",
    "            tdf[\"category\"] = DD_CATEGORIES[domain]\n",
    "\n",
    "        # Read raw similarity dataframes, average across all participants and fix column/row mixups\n",
    "        folder = f\"{RAW_DATA}/de_deyne_pairwise/pairwiseSimilarities{domain}\"\n",
    "        similarity_dfs = []\n",
    "        for i in range(len(os.listdir(folder))):\n",
    "            df = pd.read_csv(f\"{folder}/pairwiseSimilarities{domain}-{i+1}.CSV\", encoding = \"ISO-8859-1\")\n",
    "            if mixups[domain].columns_are_switched:\n",
    "                df.columns = df.columns.tolist()[:2] + df.iloc[0,2:].tolist()\n",
    "            if mixups[domain].rows_are_switched:\n",
    "                df[\"exemplar ENGLISH\"] = df.iloc[:,0].tolist()\n",
    "            similarity_dfs.append(df.iloc[1:,1:])\n",
    "        average_similarities = np.mean([df.iloc[:,1:].values.astype(int) for df in similarity_dfs], axis=0)\n",
    "        average_similarities = average_similarities + np.rot90(np.fliplr(average_similarities))\n",
    "        average_similarity_df = pd.DataFrame(average_similarities, columns=DD_CATEGORIES[domain] if domain in DD_CATEGORIES else tdf[\"category\"].tolist())\n",
    "        sdf = average_similarity_df\n",
    "        if domain in DD_CATEGORIES:\n",
    "            sdf[\"category\"] = DD_CATEGORIES[domain]\n",
    "        else:\n",
    "            sdf[\"category\"] = tdf[\"category\"].tolist()\n",
    "        col = sdf.pop(\"category\")\n",
    "        sdf.insert(0, col.name, col)\n",
    "\n",
    "        categories = [CATEGORY_RENAME[c] if c in CATEGORY_RENAME else c for c in sdf[\"category\"].tolist()]\n",
    "        keep_indices = []\n",
    "        seen = set()\n",
    "\n",
    "        # Cut all multiword or repeated categories\n",
    "        for i, category in enumerate(categories):\n",
    "            if category and \" \" not in category and category not in seen and category.isalpha():\n",
    "                keep_indices.append(i)\n",
    "            seen.add(category)\n",
    "\n",
    "        typicality_dataframes[domain] = tdf.iloc[keep_indices].reset_index(drop=True)\n",
    "        typicality_dataframes[domain][\"category\"] = [CATEGORY_RENAME[c] if c in CATEGORY_RENAME else c for c in typicality_dataframes[domain][\"category\"].tolist()]\n",
    "        typicality_dataframes[domain] = typicality_dataframes[domain].rename(CATEGORY_RENAME, axis=1)\n",
    "\n",
    "        similarity_dataframes[domain] = sdf.iloc[keep_indices, [0] + [1 + ki for ki in keep_indices]].reset_index(drop=True)\n",
    "        similarity_dataframes[domain][\"category\"] = [CATEGORY_RENAME[c] if c in CATEGORY_RENAME else c for c in similarity_dataframes[domain][\"category\"].tolist()]\n",
    "        similarity_dataframes[domain] = similarity_dataframes[domain].rename(CATEGORY_RENAME, axis=1)\n",
    "\n",
    "        assert tuple(similarity_dataframes[domain][\"category\"]) == tuple(typicality_dataframes[domain][\"category\"])\n",
    "        assert tuple(similarity_dataframes[domain][\"category\"]) == tuple(similarity_dataframes[domain].columns[1:])\n",
    "\n",
    "    return similarity_dataframes, typicality_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "bNXT8fLGsGhQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jb/hc7zn0lx6hxf267tzb1vcfq00000gn/T/ipykernel_47514/1361759950.py:16: DtypeWarning: Columns (0,1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  tdf = pd.read_csv(f\"{RAW_DATA}/de_deyne_typicality/exemplarTypicalityRatings-{domain.lower()}.CSV\", index_col=0, encoding = \"ISO-8859-1\").rename({\"Unnamed: 1\":\"category\", \"mean\": \"mean_typicality\"}, axis=1)[[\"category\", \"mean_typicality\"]].reset_index(drop=True).dropna()\n"
     ]
    }
   ],
   "source": [
    "similarity_dataframes, typicality_dataframes = generate_similarity_typicality_dataframes()\n",
    "domain_categories = {domain: df[\"category\"].tolist() for domain, df in similarity_dataframes.items()}\n",
    "\n",
    "# Pluralise categories\n",
    "for d,cs in domain_categories.items():\n",
    "    if d != \"Sports\":\n",
    "        domain_categories[d] = [ie.plural(c).capitalize() for c in cs]\n",
    "    else:\n",
    "        domain_categories[d] = [c.capitalize() for c in cs]\n",
    "for d, sdf in similarity_dataframes.items():\n",
    "    if d != \"Sports\":\n",
    "        sdf[\"category\"] = sdf[\"category\"].apply(lambda x: ie.plural(x).capitalize())\n",
    "        similarity_dataframes[d] = sdf.rename({c: ie.plural(c).capitalize() for c in sdf.columns[1:]}, axis=1)\n",
    "    else:\n",
    "        sdf[\"category\"] = sdf[\"category\"].apply(lambda x: x.capitalize())\n",
    "        similarity_dataframes[d] = sdf.rename({c: c.capitalize() for c in sdf.columns[1:]}, axis=1)\n",
    "for d, tdf in typicality_dataframes.items():\n",
    "    if d != \"Sports\":\n",
    "        tdf[\"category\"] = tdf[\"category\"].apply(lambda x: ie.plural(x).capitalize())\n",
    "    else:\n",
    "        tdf[\"category\"] = tdf[\"category\"].apply(lambda x: x.capitalize())\n",
    "\n",
    "# Similarity map for category pairs in each domain\n",
    "similarity_map = {}\n",
    "for domain in domain_categories:\n",
    "    df = similarity_dataframes[domain]\n",
    "    similarity_map[domain] = {}\n",
    "    for category1 in domain_categories[domain]:\n",
    "        similarity_map[domain][category1] = {}\n",
    "        for category2 in domain_categories[domain]:\n",
    "            if category1 == category2:\n",
    "                similarity_map[domain][category1][category2] = 20\n",
    "            else:\n",
    "                similarity_map[domain][category1][category2] = df[df[\"category\"] == category2][category1].iloc[0]\n",
    "\n",
    "# Typicality map for categories in each domain\n",
    "typicality_map = {domain: typicality_dataframes[domain].set_index(\"category\").to_dict()[\"mean_typicality\"] for domain in typicality_dataframes}\n",
    "\n",
    "# List of categories per domain, ordered by similarity to a particular category\n",
    "similarity_rank_map = {}\n",
    "for domain, cat in domain_categories.items():\n",
    "    categories = [c for c in cat if c]\n",
    "    similarity_rank_map[domain] = {}\n",
    "    for category in categories:\n",
    "        cs = [(oc, similarity_map[domain][category][oc]) for oc in categories if oc != category]\n",
    "        cs = sorted(cs, key=lambda x: x[1], reverse=True)\n",
    "        s, _ = zip(*cs)\n",
    "        similarity_rank_map[domain][category] = list(s)\n",
    "\n",
    "# List of categories per domain, ordered by typicality\n",
    "typicality_rank_map = {domain: tdf.sort_values(by=\"mean_typicality\", ascending=False)[\"category\"].tolist() for domain, tdf in typicality_dataframes.items()}\n",
    "typicality_rank_map = {domain: [c.strip() for c in dl] for domain, dl in typicality_rank_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "8HFHoloisKkG"
   },
   "outputs": [],
   "source": [
    "# List of high dis/similarity categories for each category\n",
    "high_similarity_map = {}\n",
    "high_dissimilarity_map = {}\n",
    "for domain, cat in domain_categories.items():\n",
    "    high_similarity_map[domain] = {}\n",
    "    high_dissimilarity_map[domain] = {}\n",
    "    categories = [c for c in cat if c]\n",
    "\n",
    "    sims = similarity_dataframes[domain].iloc[:,1:].values\n",
    "    sims[sims == 0] = np.nan\n",
    "    mean = np.nanmean(sims)\n",
    "    std = np.nanstd(sims)\n",
    "\n",
    "    for category in categories:\n",
    "        other_categories = [c for c in categories if c != category]\n",
    "        cs = [(oc, similarity_map[domain][category][oc]) for oc in other_categories]\n",
    "        cdf = pd.DataFrame(cs, columns=[\"category\", \"similarity\"]).sort_values(by=\"similarity\", ascending=False).dropna()\n",
    "        similar = cdf[cdf[\"similarity\"] > mean + 0.75*std][\"category\"].tolist()\n",
    "        dissimilar = cdf[cdf[\"similarity\"] < mean - 0.75*std][\"category\"].tolist()\n",
    "\n",
    "        high_similarity_map[domain][category] = similar\n",
    "        high_dissimilarity_map[domain][category] = dissimilar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vo9epxpQs7W7"
   },
   "source": [
    "## Cut DeDeyne categories\n",
    "\n",
    "Cut some categories to ensure that each domain has the same number of categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "WflQCO0cs6ws"
   },
   "outputs": [],
   "source": [
    "category_utility_map = {}\n",
    "for domain in MAIN_DOMAINS:\n",
    "    hsm = high_similarity_map[domain]\n",
    "    hdm = high_dissimilarity_map[domain]\n",
    "\n",
    "    assert set(hsm.keys()) == set(hdm.keys())\n",
    "\n",
    "    category_utility_map[domain] = {}\n",
    "    for category in hsm:\n",
    "        category_utility_map[domain][category] = len(hsm[category]) #(len(hsm[category]) + len(hdm[category])) / 2\n",
    "\n",
    "\n",
    "# Cut based on 'utility', ie. how many highly similar categories there are in the domain set\n",
    "num_arguments = min([len(category_utility_map[d]) for d in MAIN_DOMAINS])\n",
    "cut_categories = set()\n",
    "for domain in MAIN_DOMAINS:\n",
    "    categories = [x[0] for x in sorted(category_utility_map[domain].items(), key=lambda x: x[1], reverse=True)]\n",
    "    cut_categories = cut_categories.union(set(categories[num_arguments:]))\n",
    "\n",
    "domain_categories = {d: [c for c in v if c not in cut_categories] for d,v in domain_categories.items()}\n",
    "\n",
    "assert all(len(domain_categories[domain]) == num_arguments for domain in MAIN_DOMAINS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5FXnZ_3dtEdv",
    "outputId": "a74cc7e7-f25e-436e-a2fa-c1da703d7171"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Monkeys', 'Kangaroos', 'Penguins', 'Owls', 'Pigs', 'Bats'}\n"
     ]
    }
   ],
   "source": [
    "# this may be different from actual data, since the original notebook was run in colab\n",
    "print(cut_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U60-UnaRtKZ_"
   },
   "source": [
    "## Osherson Similarity data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Kipq_xwFtF8y"
   },
   "outputs": [],
   "source": [
    "osherson_similarity_df = pd.read_csv(f\"{RAW_DATA}/osherson/osherson_similarities.csv\", names=[\"c1\", \"c2\", \"similarity\"])\n",
    "osherson_similarity_map = {}\n",
    "for _, row in osherson_similarity_df.iterrows():\n",
    "    c1 = ie.plural(row[\"c1\"]).capitalize()\n",
    "    c2 = ie.plural(row[\"c2\"]).capitalize()\n",
    "    for c in (c1, c2):\n",
    "        if c not in osherson_similarity_map:\n",
    "            osherson_similarity_map[c] = {}\n",
    "    osherson_similarity_map[c1][c2] = float(row[\"similarity\"])\n",
    "    osherson_similarity_map[c2][c1] = float(row[\"similarity\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_wIA80HthWF"
   },
   "source": [
    "## Save processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "oQwhp6xatc3C"
   },
   "outputs": [],
   "source": [
    "save_map(domain_categories, f\"{PROCESSED_DATA}/domain_categories.json\")\n",
    "save_map(similarity_map, f\"{PROCESSED_DATA}/similarity_map.json\")\n",
    "save_map(osherson_similarity_map, f\"{PROCESSED_DATA}/osherson_similarity_map.json\")\n",
    "save_map(typicality_map, f\"{PROCESSED_DATA}/typicality_map.json\")\n",
    "save_map(similarity_rank_map, f\"{PROCESSED_DATA}/similarity_rank_map.json\")\n",
    "save_map(typicality_rank_map, f\"{PROCESSED_DATA}/typicality_rank_map.json\")\n",
    "save_map(high_similarity_map, f\"{PROCESSED_DATA}/high_similarity_map.json\")\n",
    "save_map(high_dissimilarity_map, f\"{PROCESSED_DATA}/high_dissimilarity_map.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8iQzaS36t2EF"
   },
   "source": [
    "# Load in Osherson and DeDeyne data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "UNvy9LYDuNiy"
   },
   "outputs": [],
   "source": [
    "domain_categories = load_map(f\"{PROCESSED_DATA}/domain_categories.json\")\n",
    "similarity_map = load_map(f\"{PROCESSED_DATA}/similarity_map.json\")\n",
    "osherson_similarity_map = load_map(f\"{PROCESSED_DATA}/osherson_similarity_map.json\")\n",
    "typicality_map = load_map(f\"{PROCESSED_DATA}/typicality_map.json\")\n",
    "similarity_rank_map = load_map(f\"{PROCESSED_DATA}/similarity_rank_map.json\")\n",
    "typicality_rank_map = load_map(f\"{PROCESSED_DATA}/typicality_rank_map.json\")\n",
    "high_similarity_map = load_map(f\"{PROCESSED_DATA}/high_similarity_map.json\")\n",
    "high_dissimilarity_map = load_map(f\"{PROCESSED_DATA}/high_dissimilarity_map.json\")\n",
    "\n",
    "# Read in original Osherson argument pair data\n",
    "osherson_df = pd.read_csv(f\"{RAW_DATA}/osherson/osherson_argument_pairs.csv\", index_col=0)\n",
    "number_map = {v:k for k,v in OSHERSON_PHENOMENON_NUMBERS.items()}\n",
    "osherson_df[\"phenomenon_number\"] = osherson_df[\"phenomenon_name\"].map(number_map)\n",
    "osherson_df[\"arg1_premises\"] = osherson_df[\"arg1_premises\"].apply(eval)\n",
    "osherson_df[\"arg2_premises\"] = osherson_df[\"arg2_premises\"].apply(eval)\n",
    "osherson_df[\"is_osherson\"] = [True]*osherson_df.shape[0]\n",
    "\n",
    "# Drop phenomenon number 9 because it uses insects\n",
    "osherson_df = osherson_df[osherson_df[\"phenomenon_number\"] != 9].reset_index(drop=True)\n",
    "\n",
    "# Read in original Osherson argument ranking data\n",
    "osherson_number_df = pd.read_csv(f\"{RAW_DATA}/osherson/premisenumbering.txt\")\n",
    "oshmap = osherson_number_df.set_index(\"number\").to_dict()[\"category\"]\n",
    "\n",
    "osdf = pd.read_csv(f\"{RAW_DATA}/osherson/specificarguments.txt\", names=[\"p1\",\"p2\",\"c\",\"strength\"], delim_whitespace=True)\n",
    "osherson_specific_df = pd.DataFrame([(\"Mammals\",\"Specific\",(oshmap[row[\"p1\"]],oshmap[row[\"p2\"]]),oshmap[row[\"c\"]],row[\"strength\"]) for _, row in osdf.iterrows()], columns=[\"domain\",\"argtype\",\"premises\",\"conclusion\",\"human_rating\"])\n",
    "osherson_specific_df[\"is_osherson\"] = [True]*osherson_specific_df.shape[0]\n",
    "\n",
    "osdf = pd.read_csv(f\"{RAW_DATA}/osherson/generalarguments.txt\", names=[\"p1\",\"p2\",\"p3\",\"strength\"], delim_whitespace=True)\n",
    "osherson_general_df = pd.DataFrame([(\"Mammals\",\"General\",(oshmap[row[\"p1\"]],oshmap[row[\"p2\"]],oshmap[row[\"p3\"]]),\"Mammals\",row[\"strength\"]) for _, row in osdf.iterrows()], columns=[\"domain\",\"argtype\",\"premises\",\"conclusion\",\"human_rating\"])\n",
    "osherson_general_df[\"is_osherson\"] = [True]*osherson_general_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9OwzNOe7uXjy"
   },
   "source": [
    "# Generate Experiment 1 argument pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "PfJAKDBAuOT8"
   },
   "outputs": [],
   "source": [
    "# Generate samples of possible arguments\n",
    "\n",
    "NUM_SAMPLES = 20000\n",
    "rows = (\n",
    "    []\n",
    ")  # (domain, phenomenon_number, sample_num, arg1_premises, arg1_conclusion, arg2_premises, arg2_conclusion)\n",
    "domains = list(domain_categories.keys())\n",
    "other_categories = {\n",
    "    \"Mammals\": domain_categories[\"Reptiles\"],\n",
    "    \"Birds\": domain_categories[\"Insects\"],\n",
    "    \"Vehicles\": domain_categories[\"Tools\"],\n",
    "}\n",
    "\n",
    "for domain in other_categories:\n",
    "    dl = domain_categories[domain]\n",
    "\n",
    "    for phenomenon_number in OSHERSON_PHENOMENON_NUMBERS:\n",
    "        for i in range(NUM_SAMPLES):\n",
    "            if phenomenon_number == 1:\n",
    "                # Premise-conclusion Similarity\n",
    "                # X|Y vs Z|Y\n",
    "                # Three categories total\n",
    "\n",
    "                c = random.choice(dl)\n",
    "                cti = typicality_rank_map[domain].index(c)\n",
    "                dissimilar = [\n",
    "                    p\n",
    "                    for p in high_dissimilarity_map[domain][c]\n",
    "                    if typicality_rank_map[domain].index(p) > cti\n",
    "                ]\n",
    "                similar = [\n",
    "                    p\n",
    "                    for p in high_similarity_map[domain][c]\n",
    "                    if typicality_rank_map[domain].index(p) > cti\n",
    "                ]\n",
    "                if not dissimilar or not similar:\n",
    "                    continue\n",
    "                p1 = random.choice(similar)\n",
    "                p2 = random.choice(dissimilar)\n",
    "                rows.append(\n",
    "                    (\n",
    "                        domain,\n",
    "                        phenomenon_number,\n",
    "                        OSHERSON_PHENOMENON_NUMBERS[phenomenon_number],\n",
    "                        i,\n",
    "                        [p1],\n",
    "                        c,\n",
    "                        [p2],\n",
    "                        c,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            elif phenomenon_number == 2:\n",
    "                # Premise Typicality\n",
    "                # X | D vs Y | D\n",
    "                # Two categories total, conclusion is domain\n",
    "\n",
    "                p1 = random.choice(typicality_rank_map[domain][:5])\n",
    "                p2 = random.choice(typicality_rank_map[domain][-5:])\n",
    "                rows.append(\n",
    "                    (\n",
    "                        domain,\n",
    "                        phenomenon_number,\n",
    "                        OSHERSON_PHENOMENON_NUMBERS[phenomenon_number],\n",
    "                        i,\n",
    "                        [p1],\n",
    "                        domain,\n",
    "                        [p2],\n",
    "                        domain,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            elif phenomenon_number == 3:\n",
    "                # Conclusion Specificity\n",
    "                # X, Y | D vs X, Y | A\n",
    "                # Two categories total, conc1 is domain, conclusion2 is some larger domain\n",
    "                sample_categories = random.sample(dl, 2)\n",
    "                p1, p2 = sample_categories\n",
    "                if domain == \"Vehicles\":\n",
    "                    c2 = \"Things\"\n",
    "                else:\n",
    "                    c2 = \"Animals\"\n",
    "                rows.append(\n",
    "                    (\n",
    "                        domain,\n",
    "                        phenomenon_number,\n",
    "                        OSHERSON_PHENOMENON_NUMBERS[phenomenon_number],\n",
    "                        i,\n",
    "                        [p1, p2],\n",
    "                        domain,\n",
    "                        [p1, p2],\n",
    "                        c2,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            elif phenomenon_number == 4:\n",
    "                # Premise Monotonicity (General)\n",
    "                # X, Y, Z | D vs X, Y | D\n",
    "                # Three categories total, conclusion is domain\n",
    "                # Sample so that third premise of first argument is not more typical than either of the first two premises\n",
    "                sample_categories = random.sample(dl, 2)\n",
    "                p1, p2 = sample_categories\n",
    "                min_typicality_index, max_typicality_index = sorted(\n",
    "                    [\n",
    "                        typicality_rank_map[domain].index(p1),\n",
    "                        typicality_rank_map[domain].index(p2),\n",
    "                    ]\n",
    "                )\n",
    "                if max_typicality_index >= len(typicality_rank_map[domain]) - 3:\n",
    "                    continue\n",
    "                p3 = random.choice(\n",
    "                    typicality_rank_map[domain][max_typicality_index + 1 :]\n",
    "                )\n",
    "                rows.append(\n",
    "                    (\n",
    "                        domain,\n",
    "                        phenomenon_number,\n",
    "                        OSHERSON_PHENOMENON_NUMBERS[phenomenon_number],\n",
    "                        i,\n",
    "                        [p1, p2, p3],\n",
    "                        domain,\n",
    "                        [p1, p2],\n",
    "                        domain,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            elif phenomenon_number == 5:\n",
    "                # Premise Monotonicity (Specific)\n",
    "                # X, Y, Z | W vs X, Y | W\n",
    "                # Four categories total\n",
    "                # Sample so that third premise of first argument is not more similar to the conclusion than either of the first two premises\n",
    "                c = random.choice(dl)\n",
    "                sample_categories = random.sample(similarity_rank_map[domain][c], 2)\n",
    "                p1, p2 = sample_categories\n",
    "                min_similar_index, max_similar_index = sorted(\n",
    "                    [\n",
    "                        similarity_rank_map[domain][c].index(p1),\n",
    "                        similarity_rank_map[domain][c].index(p2),\n",
    "                    ]\n",
    "                )\n",
    "                min_typicality_index, max_typicality_index = sorted(\n",
    "                    [\n",
    "                        typicality_rank_map[domain].index(p1),\n",
    "                        typicality_rank_map[domain].index(p2),\n",
    "                    ]\n",
    "                )\n",
    "                if (\n",
    "                    max_similar_index >= len(similarity_rank_map[domain][c]) - 3\n",
    "                    or max_typicality_index >= len(typicality_rank_map[domain]) - 3\n",
    "                ):\n",
    "                    continue\n",
    "                options = list(\n",
    "                    set(\n",
    "                        similarity_rank_map[domain][c][max_similar_index + 1 :]\n",
    "                    ).intersection(\n",
    "                        set(typicality_rank_map[domain][max_typicality_index + 1 :])\n",
    "                    )\n",
    "                )\n",
    "                if not options:\n",
    "                    continue\n",
    "                p3 = random.choice(options)\n",
    "                rows.append(\n",
    "                    (\n",
    "                        domain,\n",
    "                        phenomenon_number,\n",
    "                        OSHERSON_PHENOMENON_NUMBERS[phenomenon_number],\n",
    "                        i,\n",
    "                        [p1, p2, p3],\n",
    "                        c,\n",
    "                        [p1, p2],\n",
    "                        c,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            elif phenomenon_number == 6:\n",
    "                # Premise Diversity (General)\n",
    "                # X, Y | D vs X, Z | D\n",
    "                # Three categories total, conclusion is domain\n",
    "                # Sample second premise of first argument so that it is similar to first premise and not more typical than first premise\n",
    "                # Sample second premise of second argument so that it is dissimilar to first premise and not more typical than first premise\n",
    "                p1 = random.choice(dl)\n",
    "\n",
    "                dissimilar = high_dissimilarity_map[domain][p1]\n",
    "                similar = high_similarity_map[domain][p1]\n",
    "                if not similar or not dissimilar:\n",
    "                    continue\n",
    "                i1 = typicality_rank_map[domain].index(p1)\n",
    "                dissimilar = [\n",
    "                    ci\n",
    "                    for ci in dissimilar\n",
    "                    if typicality_rank_map[domain].index(ci) > i1\n",
    "                ]  # p2 must be less typical than p1\n",
    "                similar = [\n",
    "                    ci for ci in similar if typicality_rank_map[domain].index(ci) > i1\n",
    "                ]  # p3 must be less typical than p1\n",
    "                if not similar or not dissimilar:\n",
    "                    continue\n",
    "                p2 = random.choice(dissimilar)\n",
    "                p3 = random.choice(similar)\n",
    "\n",
    "                rows.append(\n",
    "                    (\n",
    "                        domain,\n",
    "                        phenomenon_number,\n",
    "                        OSHERSON_PHENOMENON_NUMBERS[phenomenon_number],\n",
    "                        i,\n",
    "                        [p1, p2],\n",
    "                        domain,\n",
    "                        [p1, p3],\n",
    "                        domain,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            elif phenomenon_number == 7:\n",
    "                # Premise Diversity (Specific)\n",
    "                # X, Y | W vs X, Z | W\n",
    "                # Four categories total\n",
    "                # Sample second premise of first argument so that it is dissimilar to first premise and not more similar to conclusion than first premise\n",
    "                # Sample second premise of second argument so that it is similar to first premise and not more similar to conclusion than first premise or second premise of first argument\n",
    "                c = random.choice(dl)\n",
    "                cti = typicality_rank_map[domain].index(c)\n",
    "                if cti == len(typicality_rank_map[domain]) - 1:\n",
    "                    continue\n",
    "                p1 = random.choice(typicality_rank_map[domain][cti + 1 :])\n",
    "\n",
    "                dissimilar = [\n",
    "                    p\n",
    "                    for p in high_dissimilarity_map[domain][p1]\n",
    "                    if typicality_rank_map[domain].index(p) > cti\n",
    "                ]\n",
    "                similar = [\n",
    "                    p\n",
    "                    for p in high_similarity_map[domain][p1]\n",
    "                    if typicality_rank_map[domain].index(p) > cti\n",
    "                ]\n",
    "                if not similar or not dissimilar:\n",
    "                    continue\n",
    "                i1 = similarity_rank_map[domain][c].index(p1)\n",
    "                dissimilar = [\n",
    "                    ci\n",
    "                    for ci in dissimilar\n",
    "                    if ci != c and similarity_rank_map[domain][c].index(ci) > i1\n",
    "                ]  # p2 must be less similar to c than p1\n",
    "                similar = [\n",
    "                    ci\n",
    "                    for ci in similar\n",
    "                    if ci != c and similarity_rank_map[domain][c].index(ci) > i1\n",
    "                ]  # p3 must be less similar to c than p1\n",
    "                if not similar or not dissimilar:\n",
    "                    continue\n",
    "                p2 = random.choice(dissimilar)\n",
    "                i2 = similarity_rank_map[domain][c].index(p2)\n",
    "                similar = [\n",
    "                    ci\n",
    "                    for ci in similar\n",
    "                    if ci != c and similarity_rank_map[domain][c].index(ci) > i2\n",
    "                ]  # p3 must be less similar to c than p2\n",
    "                if not similar:\n",
    "                    continue\n",
    "                p3 = random.choice(similar)\n",
    "\n",
    "                rows.append(\n",
    "                    (\n",
    "                        domain,\n",
    "                        phenomenon_number,\n",
    "                        OSHERSON_PHENOMENON_NUMBERS[phenomenon_number],\n",
    "                        i,\n",
    "                        [p1, p2],\n",
    "                        c,\n",
    "                        [p1, p3],\n",
    "                        c,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            elif phenomenon_number == 8:\n",
    "                # Nonmonotonicity (General)\n",
    "                # X, Y | D vs X, Y, Z | D\n",
    "                # Three categories total, conclusion is domain, third category is from another domain\n",
    "                sample_categories = random.sample(dl, 2)\n",
    "                p1, p2 = sample_categories\n",
    "                p3 = random.choice(other_categories[domain])\n",
    "\n",
    "                rows.append(\n",
    "                    (\n",
    "                        domain,\n",
    "                        phenomenon_number,\n",
    "                        OSHERSON_PHENOMENON_NUMBERS[phenomenon_number],\n",
    "                        i,\n",
    "                        [p1, p2],\n",
    "                        domain,\n",
    "                        [p1, p2, p3],\n",
    "                        domain,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            elif phenomenon_number == 9:\n",
    "                # Nonmonotonicity (Specific)\n",
    "                # X | Z vs X, Y | Z\n",
    "                # Three categories total, second category is from another domain\n",
    "                c = random.choice(dl)\n",
    "                cti = typicality_rank_map[domain].index(c)\n",
    "                if cti == len(typicality_rank_map[domain]) - 1:\n",
    "                    continue\n",
    "                p1 = random.choice(typicality_rank_map[domain][cti + 1 :])\n",
    "                p2 = random.choice(other_categories[domain])\n",
    "\n",
    "                rows.append(\n",
    "                    (\n",
    "                        domain,\n",
    "                        phenomenon_number,\n",
    "                        OSHERSON_PHENOMENON_NUMBERS[phenomenon_number],\n",
    "                        i,\n",
    "                        [p1],\n",
    "                        c,\n",
    "                        [p1, p2],\n",
    "                        c,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            elif phenomenon_number == 10:\n",
    "                # Premise-conclusion Asymmetry\n",
    "                # X | Y vs Y | X\n",
    "                # Two categories total\n",
    "                p1 = random.choice(typicality_rank_map[domain][:10])\n",
    "                p2 = random.choice(typicality_rank_map[domain][-10:])\n",
    "                rows.append(\n",
    "                    (\n",
    "                        domain,\n",
    "                        phenomenon_number,\n",
    "                        OSHERSON_PHENOMENON_NUMBERS[phenomenon_number],\n",
    "                        i,\n",
    "                        [p1],\n",
    "                        p2,\n",
    "                        [p2],\n",
    "                        p1,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            elif phenomenon_number == 11:\n",
    "                # Inclusion Fallacy\n",
    "                # X | D vs X | Y\n",
    "                # Two categories, first conclusion is domain\n",
    "                p1 = random.choice(typicality_rank_map[domain][:10])\n",
    "                c2 = random.choice(typicality_rank_map[domain][-10:])\n",
    "                rows.append(\n",
    "                    (\n",
    "                        domain,\n",
    "                        phenomenon_number,\n",
    "                        OSHERSON_PHENOMENON_NUMBERS[phenomenon_number],\n",
    "                        i,\n",
    "                        [p1],\n",
    "                        domain,\n",
    "                        [p1],\n",
    "                        c2,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "sample_df = pd.DataFrame(\n",
    "    rows,\n",
    "    columns=[\n",
    "        \"domain\",\n",
    "        \"phenomenon_number\",\n",
    "        \"phenomenon_name\",\n",
    "        \"sample_num\",\n",
    "        \"arg1_premises\",\n",
    "        \"arg1_conclusion\",\n",
    "        \"arg2_premises\",\n",
    "        \"arg2_conclusion\",\n",
    "    ],\n",
    ")\n",
    "sample_df.to_csv(f\"{PROCESSED_DATA}/experiment/argument_pair_samples.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "py68JiieujFu"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 269.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# Pick top 24 pairs according to SCM difference\n",
    "# Same premise set cannot appear more than 5 times\n",
    "# Same category cannot appear more than 8 times\n",
    "\n",
    "NUM_PAIRS = 24\n",
    "MAX_PSET = 10\n",
    "MAX_C = 10\n",
    "\n",
    "sample_df[\"is_osherson\"] = [False] * sample_df.shape[0]\n",
    "e1_df = pd.DataFrame([], columns=sample_df.columns)\n",
    "for dpn, sdf in tqdm.tqdm(sample_df.groupby([\"domain\", \"phenomenon_number\"])):\n",
    "    domain, phenomenon_number = dpn\n",
    "    row_indices = []\n",
    "\n",
    "    pset_counts = defaultdict(int)\n",
    "    category_counts = defaultdict(int)\n",
    "    seen = set()\n",
    "\n",
    "    tdf = pd.DataFrame([], columns=sdf.columns)\n",
    "    osh = osherson_df[\n",
    "        (osherson_df[\"phenomenon_number\"] == phenomenon_number)\n",
    "        & (osherson_df[\"domain\"] == domain)\n",
    "    ]\n",
    "    if osh.shape[0] > 0:\n",
    "        tdf = osh\n",
    "        for _, row in osh.iterrows():\n",
    "            a1p = tuple(sorted(row[\"arg1_premises\"]))\n",
    "            a2p = tuple(sorted(row[\"arg2_premises\"]))\n",
    "            pset_counts[a1p] += 1\n",
    "            pset_counts[a2p] += 1\n",
    "            seen.add((a1p, row[\"arg1_conclusion\"], a2p, row[\"arg2_conclusion\"]))\n",
    "            seen.add((a2p, row[\"arg2_conclusion\"], a1p, row[\"arg1_conclusion\"]))\n",
    "\n",
    "    i = 0\n",
    "    while i < sdf.shape[0] and len(row_indices) < NUM_PAIRS - osh.shape[0]:\n",
    "        row = sdf.iloc[i]\n",
    "        categories = (\n",
    "            row[\"arg1_premises\"]\n",
    "            + row[\"arg2_premises\"]\n",
    "            + [row[\"arg1_conclusion\"], row[\"arg2_conclusion\"]]\n",
    "        )\n",
    "        n = (\n",
    "            len(\n",
    "                [\n",
    "                    c\n",
    "                    for c in categories\n",
    "                    if category_counts[c] == MAX_C and c not in DOMAINS\n",
    "                ]\n",
    "            )\n",
    "            > 0\n",
    "        )\n",
    "        a1p = tuple(sorted(row[\"arg1_premises\"]))\n",
    "        a2p = tuple(sorted(row[\"arg2_premises\"]))\n",
    "        if (\n",
    "            pset_counts[a1p] < MAX_PSET\n",
    "            and pset_counts[a2p] < MAX_PSET\n",
    "            and (a1p, row[\"arg1_conclusion\"], a2p, row[\"arg2_conclusion\"]) not in seen\n",
    "            and (a2p, row[\"arg2_conclusion\"], a1p, row[\"arg1_conclusion\"]) not in seen\n",
    "            and row[\"arg1_conclusion\"] not in a1p\n",
    "            and row[\"arg2_conclusion\"] not in a2p\n",
    "            and len(set(a1p)) == len(a1p)\n",
    "            and len(set(a2p)) == len(a2p)\n",
    "            and not n\n",
    "        ):\n",
    "            pset_counts[a1p] += 1\n",
    "            pset_counts[a2p] += 1\n",
    "            seen.add((a1p, row[\"arg1_conclusion\"], a2p, row[\"arg2_conclusion\"]))\n",
    "            seen.add((a2p, row[\"arg2_conclusion\"], a1p, row[\"arg1_conclusion\"]))\n",
    "            for category in categories:\n",
    "                category_counts[category] += 1\n",
    "\n",
    "            row_indices.append(i)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    tdf = pd.concat([tdf, sdf.iloc[row_indices]], axis=0)\n",
    "    e1_df = pd.concat([e1_df, tdf], axis=0)\n",
    "\n",
    "\n",
    "# Shuffle Pairs\n",
    "a1_p, a2_p, a1_c, a2_c, swaps = [], [], [], [], []\n",
    "for i in range(e1_df.shape[0]):\n",
    "    swap = random.choice([True, False])\n",
    "    if swap:\n",
    "        a1_p.append(e1_df.iloc[i][\"arg2_premises\"])\n",
    "        a2_p.append(e1_df.iloc[i][\"arg1_premises\"])\n",
    "        a1_c.append(e1_df.iloc[i][\"arg2_conclusion\"])\n",
    "        a2_c.append(e1_df.iloc[i][\"arg1_conclusion\"])\n",
    "    else:\n",
    "        a1_p.append(e1_df.iloc[i][\"arg1_premises\"])\n",
    "        a2_p.append(e1_df.iloc[i][\"arg2_premises\"])\n",
    "        a1_c.append(e1_df.iloc[i][\"arg1_conclusion\"])\n",
    "        a2_c.append(e1_df.iloc[i][\"arg2_conclusion\"])\n",
    "    swaps.append(swap)\n",
    "\n",
    "e1_df[\"arg2_is_stronger\"] = swaps\n",
    "e1_df[\"arg1_premises\"] = a1_p\n",
    "e1_df[\"arg2_premises\"] = a2_p\n",
    "e1_df[\"arg1_conclusion\"] = a1_c\n",
    "e1_df[\"arg2_conclusion\"] = a2_c\n",
    "\n",
    "e1_df.reset_index(drop=True).to_csv(f\"{PROCESSED_DATA}/experiment/experiment_1.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "9RkEFIaQurdJ"
   },
   "outputs": [],
   "source": [
    "e1_df = pd.read_csv(f\"{PROCESSED_DATA}/experiment/experiment_1.csv\", index_col=0)\n",
    "\n",
    "x = [(tuple(sorted(eval(row[\"arg1_premises\"]) + eval(row[\"arg2_premises\"]))), tuple(sorted([row[\"arg1_conclusion\"], row[\"arg2_conclusion\"]]))) for _, row in e1_df.iterrows()]\n",
    "assert len(set(x)) == len(x)\n",
    "assert e1_df.shape[0] == 792\n",
    "assert all(ddf.shape[0] == 24 for _, ddf in e1_df.groupby([\"domain\", \"phenomenon_number\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dJSasoSFuxWO"
   },
   "source": [
    "# Generate Experiment 2 arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S0w9bOpSuvpa",
    "outputId": "e9f4bedd-c58c-4c19-b7fd-8748394622d5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22133it [00:01, 12712.04it/s]\n"
     ]
    }
   ],
   "source": [
    "NUM_ARGUMENTS = 100\n",
    "NUM_BINS = 10\n",
    "NUM_PREMISES = {\"Specific\": 2, \"General\": 2}\n",
    "\n",
    "# Sample sets of arguments first\n",
    "rows = []\n",
    "for domain in MAIN_DOMAINS:\n",
    "    dl = domain_categories[domain]\n",
    "\n",
    "    for argtype, num_premises in NUM_PREMISES.items():\n",
    "        for i in range(NUM_ARGUMENTS * 100):\n",
    "            categories = random.sample(dl, num_premises + 1)\n",
    "            premises = categories[:num_premises]\n",
    "            if argtype == \"Specific\":\n",
    "                conclusion = categories[-1]\n",
    "            else:\n",
    "                conclusion = domain\n",
    "\n",
    "            rows.append((domain, argtype, tuple(premises), conclusion))\n",
    "\n",
    "sample_df = pd.DataFrame(rows, columns=[\"domain\", \"argtype\", \"premises\", \"conclusion\"])\n",
    "sample_df = sample_df.drop_duplicates()\n",
    "\n",
    "# Calculate SCM\n",
    "scm_rows = []\n",
    "for _, row in tqdm.tqdm(sample_df.iterrows()):\n",
    "    scm_score = scm(\n",
    "        row[\"premises\"],\n",
    "        row[\"conclusion\"],\n",
    "        domain_categories[row[\"domain\"]],\n",
    "        similarity_map[row[\"domain\"]],\n",
    "        row[\"argtype\"] == \"Specific\",\n",
    "        alpha=0.5,\n",
    "    )\n",
    "    scm_rows.append(scm_score)\n",
    "\n",
    "sample_df[\"scm\"] = scm_rows\n",
    "\n",
    "sample_df.to_csv(f\"{PROCESSED_DATA}/experiment/argument_samples.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "hqyznI4Zu6YM"
   },
   "outputs": [],
   "source": [
    "# Stratified sampling\n",
    "# Each premise set cannot appear more than four times\n",
    "# Each category cannot appear more than fifteen times\n",
    "\n",
    "\n",
    "def generate_experiment2_arguments(num_bins: int) -> pd.DataFrame:\n",
    "    MAX_PSET = 4\n",
    "    MAX_CATEGORY = 15\n",
    "\n",
    "    cols = [\"domain\", \"argtype\", \"premises\", \"conclusion\", \"scm\"]\n",
    "    e2_df = pd.DataFrame([], columns=cols)\n",
    "    for da, tdf in sample_df.groupby([\"domain\", \"argtype\"]):\n",
    "        domain, argtype = da\n",
    "\n",
    "        pset_counts = defaultdict(int)\n",
    "        category_counts = defaultdict(int)\n",
    "        seen = set()\n",
    "\n",
    "        num_arguments = NUM_ARGUMENTS\n",
    "\n",
    "        rows = []\n",
    "\n",
    "        # Split arguments into bins\n",
    "        tdf[\"bin\"] = pd.cut(tdf[\"scm\"], num_bins, labels=False)\n",
    "\n",
    "        while len(rows) < num_arguments:\n",
    "            binlabels = list(range(num_bins))\n",
    "            random.shuffle(binlabels)\n",
    "\n",
    "            for binlabel in binlabels:\n",
    "                bdf = tdf[tdf[\"bin\"] == binlabel]\n",
    "\n",
    "                for i, row in bdf.iterrows():\n",
    "                    premises, conclusion = row[\"premises\"], row[\"conclusion\"]\n",
    "                    sorted_premises = tuple(sorted(premises))\n",
    "                    categories = list(premises) + [conclusion]\n",
    "                    n = (\n",
    "                        len(\n",
    "                            [\n",
    "                                c\n",
    "                                for c in categories\n",
    "                                if category_counts[c] >= MAX_CATEGORY\n",
    "                                and c not in DOMAINS\n",
    "                            ]\n",
    "                        )\n",
    "                        > 0\n",
    "                    )\n",
    "                    if (\n",
    "                        (sorted_premises, conclusion) not in seen\n",
    "                        and pset_counts[sorted_premises] < MAX_PSET\n",
    "                        and not n\n",
    "                    ):\n",
    "                        seen.add((sorted_premises, conclusion))\n",
    "                        pset_counts[sorted_premises] += 1\n",
    "                        for c in categories:\n",
    "                            category_counts[c] += 1\n",
    "                        rows.append((domain, argtype, premises, conclusion, row[\"scm\"]))\n",
    "                        break\n",
    "\n",
    "                if len(rows) == num_arguments:\n",
    "                    break\n",
    "\n",
    "        bdf = pd.DataFrame(rows, columns=cols)\n",
    "        bdf[\"is_osherson\"] = [0] * bdf.shape[0]\n",
    "\n",
    "        for _, tdf in bdf.groupby([\"domain\", \"argtype\"]):\n",
    "            x = Counter([tuple(sorted(list(p))) for p in tdf[\"premises\"].tolist()])\n",
    "            assert all(c <= MAX_PSET for c in x.values())\n",
    "            x = Counter([a for b in tdf[\"premises\"].tolist() for a in b])\n",
    "            assert all([c <= MAX_CATEGORY for c in x.values()])\n",
    "\n",
    "        if domain == \"Mammals\":\n",
    "            # if argtype == \"General\":\n",
    "            #   bdf = pd.concat([bdf, osherson_general_df], axis=0)\n",
    "            if argtype == \"Specific\":\n",
    "                bdf = pd.concat([bdf, osherson_specific_df], axis=0)\n",
    "        bdf = bdf.sample(frac=1)\n",
    "\n",
    "        e2_df = pd.concat([e2_df, bdf], axis=0)\n",
    "\n",
    "    return e2_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "e2_df = generate_experiment2_arguments(NUM_BINS)\n",
    "e2_df[\"premises\"] = [\n",
    "    tuple([ie.plural(p).capitalize() for p in row[\"premises\"]])\n",
    "    if row[\"is_osherson\"] == 1\n",
    "    else row[\"premises\"]\n",
    "    for _, row in e2_df.iterrows()\n",
    "]\n",
    "e2_df[\"conclusion\"] = [\n",
    "    ie.plural(row[\"conclusion\"]).capitalize()\n",
    "    if row[\"is_osherson\"] == 1 and row[\"argtype\"] == \"Specific\"\n",
    "    else row[\"conclusion\"]\n",
    "    for _, row in e2_df.iterrows()\n",
    "]\n",
    "e2_df.sort_values(by=[\"domain\", \"argtype\", \"scm\"]).to_csv(\n",
    "    f\"{PROCESSED_DATA}/experiment/experiment_2.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "3IpIlgpivDlP"
   },
   "outputs": [],
   "source": [
    "e2_df = pd.read_csv(f\"{PROCESSED_DATA}/experiment/experiment_2.csv\", index_col=0)\n",
    "e2_df[\"premises\"] = e2_df[\"premises\"].apply(eval)\n",
    "\n",
    "for da, tdf in e2_df.groupby([\"domain\", \"argtype\", \"is_osherson\"]):\n",
    "    domain, argtype, is_osherson = da\n",
    "    premises = set([a for b in tdf[\"premises\"].tolist() for a in b])\n",
    "    conclusions = set([c for c in tdf[\"conclusion\"].tolist() if c not in DOMAINS])\n",
    "    assert len(premises.union(conclusions)) <= 24\n",
    "    if not is_osherson:\n",
    "        assert tdf.shape[0] == NUM_ARGUMENTS\n",
    "    elif argtype == \"Specific\":\n",
    "        assert tdf.shape[0] == osherson_specific_df.shape[0]\n",
    "    else:  # General\n",
    "        assert tdf.shape[0] == osherson_general_df.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wPwKIJUmvIM9"
   },
   "source": [
    "# Generate experiment JSONS\n",
    "\n",
    "Here we divide our sets of argument pairs and arguments into batches of stimuli for every individual participant, packaging all of this up into JSON files that can be used to run the behavioural experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "Kil05HmUvG7k"
   },
   "outputs": [],
   "source": [
    "e1_df = pd.read_csv(f\"{PROCESSED_DATA}/experiment/experiment_1.csv\", index_col=0)\n",
    "e2_df = pd.read_csv(f\"{PROCESSED_DATA}/experiment/experiment_2.csv\", index_col=0)\n",
    "\n",
    "e1_df[\"arg1_premises\"] = e1_df[\"arg1_premises\"].apply(eval)\n",
    "e1_df[\"arg2_premises\"] = e1_df[\"arg2_premises\"].apply(eval)\n",
    "e2_df[\"premises\"] = e2_df[\"premises\"].apply(lambda x: list(eval(x)))\n",
    "\n",
    "e2_df = e2_df.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def generate_mturk_index_file(out, filename):\n",
    "    df = pd.DataFrame(\n",
    "        [(i, out[i][\"tid\"]) for i in range(len(out))], columns=[\"index\", \"tid\"]\n",
    "    )\n",
    "    df.to_csv(filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Egy1ZpAvihi"
   },
   "source": [
    "## Generate property file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "o8V6stdavdoj"
   },
   "outputs": [],
   "source": [
    "PROPERTY_ID = \"property_p\"\n",
    "\n",
    "\n",
    "class PropertyGenerator(ABC):\n",
    "    @abstractmethod\n",
    "    def property_id(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def generate_property(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class PropertyPGenerator(PropertyGenerator):\n",
    "    def property_id(self):\n",
    "        return \"property_p\"\n",
    "\n",
    "    def generate_property(self):\n",
    "        return \"property P\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "5EHoQswfvoSu"
   },
   "outputs": [],
   "source": [
    "property_generator = PropertyPGenerator()\n",
    "\n",
    "out = f\"\"\"\n",
    "PROPERTY_SET = {'{'}\n",
    "  {property_generator.property_id()}: {'{'}\n",
    "    id: {property_generator.property_id()},\n",
    "    positive: '$c have {property_generator.generate_property()}',\n",
    "    negative: '$c don't {property_generator.generate_property()}'\n",
    "  {'}'}\n",
    "{'}'}\n",
    "\"\"\"\n",
    "\n",
    "with open(f\"{PROCESSED_DATA}/experiment_json/jsons/csr_properties.json\", 'w') as file:\n",
    "    file.write(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W19Bm-7_wL5q"
   },
   "source": [
    "## Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "avYHOSyav-Ut"
   },
   "outputs": [],
   "source": [
    "SIZE = 2  # Number of pairs per phenomena/domain that each participant should see\n",
    "NUM_PAIRS = 24  # Total number of pairs per phenomena/domain\n",
    "\n",
    "rows = []\n",
    "for uid in range(math.ceil(NUM_PAIRS / SIZE)):\n",
    "    indices = []\n",
    "    for _, pdf in e1_df.groupby([\"phenomenon_number\", \"domain\"]):\n",
    "        indices += (\n",
    "            pdf.sample(frac=1, random_state=0)\n",
    "            .iloc[uid * SIZE : uid * SIZE + SIZE]\n",
    "            .index.tolist()\n",
    "        )\n",
    "    random.shuffle(indices)\n",
    "    rows.append((uid, indices))\n",
    "index_df = pd.DataFrame(rows, columns=[\"participant_id\", \"indices\"])\n",
    "index_df.to_csv(f\"{PROCESSED_DATA}/experiment_json/experiment_1_participant_splits.csv\")\n",
    "\n",
    "# 2 pairs per phenomena (11 total) and domain (3 total) combo\n",
    "assert all(len(i) == SIZE * 11 * 3 for i in index_df[\"indices\"])\n",
    "\n",
    "# No overlaps between splits\n",
    "assert len(set([a for b in index_df[\"indices\"].tolist() for a in b])) == len(\n",
    "    [a for b in index_df[\"indices\"].tolist() for a in b]\n",
    ")\n",
    "\n",
    "# Final splits include all pairs\n",
    "assert sorted(\n",
    "    [a for b in index_df[\"indices\"].tolist() for a in b], reverse=False\n",
    ") == list(range(e1_df.shape[0]))\n",
    "\n",
    "# All phenomena/domain pairs are present in the right amount in each split\n",
    "assert all(\n",
    "    all(\n",
    "        vc == SIZE\n",
    "        for vc in e1_df.iloc[index_df[\"indices\"].iloc[0]].value_counts(\n",
    "            [\"domain\", \"phenomenon_number\"]\n",
    "        )\n",
    "    )\n",
    "    for i in index_df[\"indices\"]\n",
    ")\n",
    "\n",
    "test_cases = [\n",
    "    (x[0][0][0], x[0][1], x[1][1]) if not f else (x[0][0][0], x[1][1], x[0][1])\n",
    "    for x, f in EXPERIMENT_1_CONTROLS.items()\n",
    "]\n",
    "\n",
    "index_df = pd.read_csv(\n",
    "    f\"{PROCESSED_DATA}/experiment_json/experiment_1_participant_splits.csv\", index_col=0\n",
    ")\n",
    "index_df[\"indices\"] = index_df[\"indices\"].apply(eval)\n",
    "\n",
    "participant_df = index_df\n",
    "for _ in range(NUM_PARTICIPANTS_PER_TRIAL - 1):\n",
    "    participant_df = pd.concat([participant_df, index_df], axis=0)\n",
    "participant_df = participant_df.reset_index(drop=True)\n",
    "participant_df[\"participant_id\"] = list(range(participant_df.shape[0]))\n",
    "\n",
    "assert participant_df.shape[0] == NUM_PARTICIPANTS_PER_TRIAL * NUM_PAIRS / SIZE\n",
    "assert len(set([tuple(i) for i in participant_df[\"indices\"]])) == index_df.shape[0]\n",
    "\n",
    "out = []\n",
    "for j, irow in participant_df.iterrows():\n",
    "    uid = irow[\"participant_id\"]\n",
    "    user_trials = {\"tid\": f\"tid_experiment1_{uid}\"}\n",
    "    trial_config = []\n",
    "    c, i = 0, 0\n",
    "    t = len(irow[\"indices\"]) // 4\n",
    "    for _, row in (\n",
    "        e1_df.iloc[irow[\"indices\"]]\n",
    "        .sample(frac=1, random_state=j)\n",
    "        .reset_index(drop=True)\n",
    "        .iterrows()\n",
    "    ):\n",
    "        user_trial = {\"id\": f\"tc{i}\"}\n",
    "        arguments = []\n",
    "        arguments.append(\n",
    "            {\n",
    "                \"property\": property_generator.property_id(),\n",
    "                \"premises\": [p for p in row[\"arg1_premises\"]],\n",
    "                \"conclusion\": row[\"arg1_conclusion\"],\n",
    "            }\n",
    "        )\n",
    "        arguments.append(\n",
    "            {\n",
    "                \"property\": property_generator.property_id(),\n",
    "                \"premises\": [p for p in row[\"arg2_premises\"]],\n",
    "                \"conclusion\": row[\"arg2_conclusion\"],\n",
    "            }\n",
    "        )\n",
    "        user_trial[\"arguments\"] = arguments\n",
    "        trial_config.append(user_trial)\n",
    "        i += 1\n",
    "\n",
    "        if i % t == 0 and c < len(test_cases):\n",
    "            # Add test case\n",
    "            user_trial = {\"id\": f\"tc{i}\"}\n",
    "            arguments = []\n",
    "            arguments.append(\n",
    "                {\n",
    "                    \"property\": property_generator.property_id(),\n",
    "                    \"premises\": [test_cases[c][0]],\n",
    "                    \"conclusion\": test_cases[c][1],\n",
    "                }\n",
    "            )\n",
    "            arguments.append(\n",
    "                {\n",
    "                    \"property\": property_generator.property_id(),\n",
    "                    \"premises\": [test_cases[c][0]],\n",
    "                    \"conclusion\": test_cases[c][2],\n",
    "                }\n",
    "            )\n",
    "            user_trial[\"arguments\"] = arguments\n",
    "            trial_config.append(user_trial)\n",
    "            c += 1\n",
    "            i += 1\n",
    "\n",
    "    assert len(trial_config) == 11 * SIZE * 3 + len(test_cases)\n",
    "\n",
    "    user_trials[\"cbi_compare\"] = {\"trialConfig\": trial_config}\n",
    "    out.append(user_trials)\n",
    "\n",
    "\n",
    "with open(f\"{PROCESSED_DATA}/experiment_json/experiment_1.json\", \"w\") as file:\n",
    "    file.write(json.dumps(out, indent=2))\n",
    "generate_mturk_index_file(out, f\"{PROCESSED_DATA}/experiment_json/experiment_1.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHMJfi6Hwor4"
   },
   "source": [
    "## Experiment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aUxBJEHjwus4"
   },
   "source": [
    "### Generate trial arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "VJGZpe-LwiJ_"
   },
   "outputs": [],
   "source": [
    "PREDEFINED_TRIALS = {\n",
    "    \"training_1_0\": {\n",
    "        \"id\": \"training_1_0\",\n",
    "        \"intro\": \"intro 1\",\n",
    "        \"arguments\": [\n",
    "            {\n",
    "                \"property\": \"property_p\",\n",
    "                \"premises\": [\"Papayas\"],\n",
    "                \"conclusion\": \"All fruits\",\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "    \"training_1_1\": {\n",
    "        \"id\": \"training_1_1\",\n",
    "        \"intro\": \"outro 1\",\n",
    "        \"arguments\": [\n",
    "            {\n",
    "                \"property\": \"property_p\",\n",
    "                \"premises\": [\"Apples\"],\n",
    "                \"conclusion\": \"All fruits\",\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "    \"training_2_0\": {\n",
    "        \"id\": \"training_2_0\",\n",
    "        \"intro\": \"intro 2\",\n",
    "        \"arguments\": [\n",
    "            {\n",
    "                \"property\": \"property_p\",\n",
    "                \"premises\": [\"Lemons\", \"Limes\"],\n",
    "                \"conclusion\": \"All fruits\",\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "    \"training_2_1\": {\n",
    "        \"id\": \"training_2_1\",\n",
    "        \"intro\": \"outro 2\",\n",
    "        \"arguments\": [\n",
    "            {\n",
    "                \"property\": \"property_p\",\n",
    "                \"premises\": [\"Bananas\", \"Watermelons\"],\n",
    "                \"conclusion\": \"All fruits\",\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "    \"training_3_0\": {\n",
    "        \"id\": \"training_3_0\",\n",
    "        \"intro\": \"intro 1\",\n",
    "        \"arguments\": [\n",
    "            {\n",
    "                \"property\": \"property_p\",\n",
    "                \"premises\": [\"Blackberries\"],\n",
    "                \"conclusion\": \"Raspberries\",\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "    \"training_3_1\": {\n",
    "        \"id\": \"training_3_1\",\n",
    "        \"intro\": \"outro 1\",\n",
    "        \"arguments\": [\n",
    "            {\n",
    "                \"property\": \"property_p\",\n",
    "                \"premises\": [\"Pineapples\"],\n",
    "                \"conclusion\": \"Raspberries\",\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "    \"training_4_0\": {\n",
    "        \"id\": \"training_4_0\",\n",
    "        \"intro\": \"intro 2\",\n",
    "        \"arguments\": [\n",
    "            {\n",
    "                \"property\": \"property_p\",\n",
    "                \"premises\": [\"Lemons\", \"Limes\"],\n",
    "                \"conclusion\": \"Cherries\",\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "    \"training_4_1\": {\n",
    "        \"id\": \"training_4_1\",\n",
    "        \"intro\": \"outro 2\",\n",
    "        \"arguments\": [\n",
    "            {\n",
    "                \"property\": \"property_p\",\n",
    "                \"premises\": [\"Bananas\", \"Watermelons\"],\n",
    "                \"conclusion\": \"Cherries\",\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "}\n",
    "\n",
    "save_map(\n",
    "    PREDEFINED_TRIALS,\n",
    "    f\"{PROCESSED_DATA}/experiment_json/jsons/experiment_2_predefined_trials.json\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pmhKG6Sewz1O"
   },
   "source": [
    "## Generate splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "DxsoLBqDwxmJ"
   },
   "outputs": [],
   "source": [
    "# Split arguments into quantile based bins based on SCM\n",
    "NUM_BINS = 10\n",
    "df = pd.DataFrame([], columns=e2_df.columns.tolist())\n",
    "for _, tdf in e2_df.groupby([\"domain\", \"argtype\", \"is_osherson\"]):\n",
    "    if tdf[\"is_osherson\"].iloc[0] == 1:\n",
    "        tdf[\"bin\"] = pd.qcut(tdf[\"human_rating\"], NUM_BINS, labels=False)\n",
    "    else:\n",
    "        tdf[\"bin\"] = pd.qcut(tdf[\"scm\"], NUM_BINS, labels=False)\n",
    "    df = pd.concat([df, tdf], axis=0)\n",
    "\n",
    "# Turn bins into argument batches\n",
    "batches = {}  # {(domain, argtype, batchnum): [list of arguments]}\n",
    "for ado, ddf in df.groupby([\"argtype\", \"domain\", \"is_osherson\"]):\n",
    "    argtype, domain, is_osherson = ado\n",
    "    max_batch_size = ddf[\"bin\"].value_counts().max()\n",
    "\n",
    "    for i in range(max_batch_size):\n",
    "        batch = []\n",
    "        for b, bdf in ddf.groupby(\"bin\"):\n",
    "            try:\n",
    "                batch.append(bdf.iloc[i][[\"premises\", \"conclusion\"]].values.tolist())\n",
    "            except:\n",
    "                batch.append(\n",
    "                    bdf.sample(1).iloc[0][[\"premises\", \"conclusion\"]].values.tolist()\n",
    "                )\n",
    "        batches[(domain, argtype, is_osherson, i)] = batch\n",
    "\n",
    "rows = []\n",
    "for daob, arguments in batches.items():\n",
    "    domain, argtype, is_osherson, batch_num = daob\n",
    "    for argument in arguments:\n",
    "        rows.append((batch_num, domain, argtype, is_osherson, argument))\n",
    "batch_df = pd.DataFrame(\n",
    "    rows, columns=[\"batch_num\", \"domain\", \"argtype\", \"is_osherson\", \"argument\"]\n",
    ")\n",
    "batch_df[\"argstr\"] = batch_df[\"argument\"].apply(str)\n",
    "\n",
    "assert all(\n",
    "    len(tdf[\"argstr\"].unique()) == 10\n",
    "    for _, tdf in batch_df.groupby([\"batch_num\", \"domain\", \"argtype\", \"is_osherson\"])\n",
    ")\n",
    "assert all(\n",
    "    len(tdf[\"argstr\"].unique()) == 100\n",
    "    for _, tdf in batch_df[batch_df[\"is_osherson\"] == 0].groupby([\"domain\", \"argtype\"])\n",
    ")\n",
    "\n",
    "\n",
    "# Generate single premise arguments\n",
    "def generate_single_prem_args(batch):\n",
    "    \"\"\"\n",
    "    batch: [[[p1,p2,p3], c], ...]\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for p, c in batch:\n",
    "        for px in p:\n",
    "            out.append((px, c))\n",
    "    return list(set(out))\n",
    "\n",
    "\n",
    "all_single_prem_args = {}  # {(domain, argtype, is_osherson): [list of arguments]}\n",
    "for dao, tdf in batch_df.groupby([\"domain\", \"argtype\", \"is_osherson\"]):\n",
    "    single_prem_args = generate_single_prem_args(tdf[\"argument\"].tolist())\n",
    "    all_single_prem_args[dao] = single_prem_args\n",
    "    random.shuffle(all_single_prem_args[dao])\n",
    "\n",
    "# Add single premise arguments into batch_df\n",
    "df = pd.DataFrame([], columns=batch_df.columns)\n",
    "for bdao, bdf in batch_df.groupby([\"batch_num\", \"domain\", \"argtype\", \"is_osherson\"]):\n",
    "    batch_num, domain, argtype, is_osherson = bdao\n",
    "\n",
    "    # Generate single premise arguments corresponding to this batch's multi premise arguments\n",
    "    single_prem_args = generate_single_prem_args(bdf[\"argument\"].tolist())\n",
    "    num_single_prem_args = len(single_prem_args)\n",
    "\n",
    "    # Number of single premise arguments that we want\n",
    "    n = NUM_SINGLE_PREMISE_ARGS_PER_BATCH\n",
    "    assert num_single_prem_args <= n\n",
    "\n",
    "    if num_single_prem_args < n:\n",
    "        # Need to pad our single premise args with single premise args from other batches\n",
    "\n",
    "        if not is_osherson:\n",
    "            # Randomly sample single premise arguments from other batches\n",
    "            \n",
    "            single_prem_args += random.sample(\n",
    "                list(set(all_single_prem_args[(domain, argtype, is_osherson)]).difference(\n",
    "                    set(single_prem_args)\n",
    "                )),\n",
    "                k=n - len(single_prem_args),\n",
    "            )\n",
    "            \n",
    "            assert len(single_prem_args) == n\n",
    "\n",
    "        elif argtype == \"Specific\":\n",
    "            single_prem_args = all_single_prem_args[(domain, argtype, 1)]\n",
    "\n",
    "    random.shuffle(single_prem_args)\n",
    "    tdf = pd.DataFrame(\n",
    "        [\n",
    "            (batch_num, domain, argtype, is_osherson, [[spa[0]], spa[1]])\n",
    "            for spa in single_prem_args\n",
    "        ],\n",
    "        columns=[\"batch_num\", \"domain\", \"argtype\", \"is_osherson\", \"argument\"],\n",
    "    )\n",
    "    tdf[\"argstr\"] = tdf[\"argument\"].apply(str)\n",
    "    df = pd.concat([df, bdf, tdf], axis=0)\n",
    "\n",
    "assert all(\n",
    "    bdf.shape[0] == 34\n",
    "    for _, bdf in df[df[\"is_osherson\"] == 0].groupby(\n",
    "        [\"batch_num\", \"domain\", \"argtype\", \"is_osherson\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "df[\"is_single_premise\"] = df[\"argument\"].apply(lambda x: len(x[0]) == 1)\n",
    "\n",
    "assert all(\n",
    "    len(tdf[tdf[\"is_osherson\"] == 0][\"argstr\"].unique()) == 100\n",
    "    for _, tdf in df[~df[\"is_single_premise\"]].groupby([\"domain\", \"argtype\"])\n",
    ")\n",
    "assert (\n",
    "    len(\n",
    "        df[\n",
    "            (df[\"is_osherson\"] == 1)\n",
    "            & (df[\"argtype\"] == \"Specific\")\n",
    "            & (~df[\"is_single_premise\"])\n",
    "        ][\"argstr\"].unique()\n",
    "    )\n",
    "    == osherson_specific_df.shape[0]\n",
    ")\n",
    "assert (\n",
    "    len(df[(df[\"is_osherson\"] == 1) & (df[\"argtype\"] == \"General\")][\"argstr\"].unique())\n",
    "    == 0\n",
    ")\n",
    "\n",
    "df[\n",
    "    [\"batch_num\", \"domain\", \"argtype\", \"is_osherson\", \"is_single_premise\", \"argument\"]\n",
    "].to_csv(f\"{PROCESSED_DATA}/experiment_json/experiment_2_participant_splits.csv\")\n",
    "\n",
    "batch_df = pd.read_csv(\n",
    "    f\"{PROCESSED_DATA}/experiment_json/experiment_2_participant_splits.csv\", index_col=0\n",
    ")\n",
    "batch_df[\"argument\"] = batch_df[\"argument\"].apply(eval)\n",
    "\n",
    "\n",
    "def generate_argument_trial(tid, premises, conclusion, breakAfter=False):\n",
    "    return {\n",
    "        \"id\": f\"tc{tid}\",\n",
    "        \"breakAfter\": breakAfter,\n",
    "        \"arguments\": [\n",
    "            {\n",
    "                \"property\": \"property_p\",\n",
    "                \"premises\": premises,\n",
    "                \"conclusion\": conclusion,\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "\n",
    "\n",
    "# Show a 'test' trial every N trials\n",
    "TEST_SPACING = 8\n",
    "NUM_TESTS = 4\n",
    "\n",
    "rows = []\n",
    "for is_osherson, o_df in batch_df.groupby([\"is_osherson\"]):\n",
    "    output = []\n",
    "\n",
    "    pid = 0\n",
    "\n",
    "    for single_premise_first in (True, False):\n",
    "        for bda, batch in o_df.groupby([\"batch_num\", \"domain\", \"argtype\"]):\n",
    "            batch_num, domain, argtype = bda\n",
    "\n",
    "            experiment_grouping = \"dedeyne\" if not is_osherson else \"osherson\"\n",
    "\n",
    "            for _ in range(NUM_PARTICIPANTS_PER_TRIAL // 2):\n",
    "                multi_premise_args = batch[~batch[\"is_single_premise\"]][\n",
    "                    \"argument\"\n",
    "                ].tolist()\n",
    "                single_premise_args = batch[batch[\"is_single_premise\"]][\n",
    "                    \"argument\"\n",
    "                ].tolist()\n",
    "                random.shuffle(multi_premise_args)\n",
    "                random.shuffle(single_premise_args)\n",
    "\n",
    "                p_trial = {\n",
    "                    \"tid\": f\"tid_experiment2_{experiment_grouping}_participant{pid}\",\n",
    "                    \"cbi_rate\": {\"trialConfig\": []},\n",
    "                }\n",
    "\n",
    "                if single_premise_first:\n",
    "                    arglist = [single_premise_args, multi_premise_args]\n",
    "                else:\n",
    "                    arglist = [multi_premise_args, single_premise_args]\n",
    "\n",
    "                tid, t = 0, 0\n",
    "                is_single_premise = single_premise_first\n",
    "                for args in arglist:\n",
    "                    # Place trial args first\n",
    "                    pt = \"single_premise\" if is_single_premise else \"multi_premise\"\n",
    "                    p_trial[\"cbi_rate\"][\"trialConfig\"] += EXPERIMENT_2_TRAINING_TRIALS[\n",
    "                        argtype\n",
    "                    ][pt]\n",
    "\n",
    "                    for arg in args:\n",
    "                        premises = [p.capitalize() for p in arg[0]]\n",
    "                        if argtype == \"General\":\n",
    "                            conclusion = f\"All {arg[1].lower()}\"\n",
    "                        else:\n",
    "                            conclusion = arg[1].capitalize()\n",
    "\n",
    "                        a_trial = generate_argument_trial(tid, premises, conclusion)\n",
    "                        p_trial[\"cbi_rate\"][\"trialConfig\"].append(a_trial)\n",
    "                        rows.append(\n",
    "                            (\n",
    "                                pid,\n",
    "                                tid,\n",
    "                                domain,\n",
    "                                argtype,\n",
    "                                is_osherson,\n",
    "                                batch_num,\n",
    "                                premises,\n",
    "                                conclusion,\n",
    "                            )\n",
    "                        )\n",
    "                        tid += 1\n",
    "\n",
    "                        if tid % TEST_SPACING == 0 and t < NUM_TESTS:\n",
    "                            if is_single_premise:\n",
    "                                test_arg = EXPERIMENT_2_SINGLE_PREMISE_CONTROLS[\n",
    "                                    argtype\n",
    "                                ][domain]\n",
    "                                a_trial = generate_argument_trial(\n",
    "                                    tid, [test_arg[t][0]], test_arg[t][1]\n",
    "                                )\n",
    "                                rows.append(\n",
    "                                    (\n",
    "                                        pid,\n",
    "                                        tid,\n",
    "                                        domain,\n",
    "                                        argtype,\n",
    "                                        is_osherson,\n",
    "                                        batch_num,\n",
    "                                        [test_arg[t][0]],\n",
    "                                        test_arg[t][1],\n",
    "                                    )\n",
    "                                )\n",
    "                                t += 1\n",
    "                            else:\n",
    "                                test_arg = EXPERIMENT_2_MULTI_PREMISE_CONTROLS[argtype][\n",
    "                                    domain\n",
    "                                ]\n",
    "                                a_trial = generate_argument_trial(\n",
    "                                    tid, test_arg[0], test_arg[1]\n",
    "                                )\n",
    "                                rows.append(\n",
    "                                    (\n",
    "                                        pid,\n",
    "                                        tid,\n",
    "                                        domain,\n",
    "                                        argtype,\n",
    "                                        is_osherson,\n",
    "                                        batch_num,\n",
    "                                        test_arg[0],\n",
    "                                        test_arg[1],\n",
    "                                    )\n",
    "                                )\n",
    "\n",
    "                            p_trial[\"cbi_rate\"][\"trialConfig\"].append(a_trial)\n",
    "                            tid += 1\n",
    "\n",
    "                    is_single_premise = not is_single_premise\n",
    "\n",
    "                # Set breakAfter\n",
    "                arg_is_single = single_premise_first\n",
    "                prev_trial = None\n",
    "                for trial in p_trial[\"cbi_rate\"][\"trialConfig\"]:\n",
    "                    if type(trial) == dict:\n",
    "                        current_arg_is_single = (\n",
    "                            len(trial[\"arguments\"][0][\"premises\"]) == 1\n",
    "                        )\n",
    "                        if current_arg_is_single != arg_is_single:\n",
    "                            prev_trial[\"breakAfter\"] = True\n",
    "                            break\n",
    "\n",
    "                        arg_is_single = current_arg_is_single\n",
    "                        prev_trial = trial\n",
    "\n",
    "                output.append(p_trial)\n",
    "                pid += 1\n",
    "\n",
    "    with open(\n",
    "        f\"{PROCESSED_DATA}/experiment_json/jsons/{experiment_grouping}_experiment_2.json\",\n",
    "        \"w\",\n",
    "    ) as file:\n",
    "        file.write(json.dumps(output, indent=2))\n",
    "    generate_mturk_index_file(\n",
    "        output,\n",
    "        f\"{PROCESSED_DATA}/experiment_json/jsons/{experiment_grouping}_experiment_2_index.csv\",\n",
    "    )\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    rows,\n",
    "    columns=[\n",
    "        \"pid\",\n",
    "        \"tid\",\n",
    "        \"domain\",\n",
    "        \"conclusion_type\",\n",
    "        \"is_osherson\",\n",
    "        \"batch_number\",\n",
    "        \"premises\",\n",
    "        \"conclusion\",\n",
    "    ],\n",
    ")\n",
    "df.to_csv(f\"{PROCESSED_DATA}/experiment_json/experiment_2.csv\")\n",
    "\n",
    "df = pd.read_csv(f\"{PROCESSED_DATA}/experiment_json/experiment_2.csv\", index_col=0)\n",
    "df = df[df[\"is_osherson\"] == 0]\n",
    "\n",
    "for dct, ddf in df.groupby([\"domain\", \"conclusion_type\"]):\n",
    "    domain, conclusion_type = dct\n",
    "    tids = [\n",
    "        f\"tid_experiment2_dedeyne_participant{pid}\" for pid, _ in ddf.groupby(\"pid\")\n",
    "    ]\n",
    "    pd.DataFrame(tids, columns=[\"tid\"]).to_csv(\n",
    "        f\"{PROCESSED_DATA}/experiment_json/jsons/dedeyne_experiment_2_{domain.lower()}_{conclusion_type.lower()}_index.csv\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kdry3To6TYlW"
   },
   "source": [
    "# Clean Experiment 1 human data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "QXJcvDsKxAyQ"
   },
   "outputs": [],
   "source": [
    "def pluralise_osherson_conclusion(conclusion: str):\n",
    "    if conclusion in (\"Mammals\", \"Birds\", \"Animals\"):\n",
    "        return f\"All {conclusion.lower()}\"\n",
    "    else:\n",
    "        return ie.plural(conclusion).capitalize()\n",
    "\n",
    "\n",
    "osherson_arg2_stronger = set(\n",
    "    [\n",
    "        (\n",
    "            (\n",
    "                \":\".join([ie.plural(p).capitalize() for p in row[\"arg2_premises\"]]),\n",
    "                pluralise_osherson_conclusion(row[\"arg2_conclusion\"]),\n",
    "            ),\n",
    "            (\n",
    "                \":\".join([ie.plural(p).capitalize() for p in row[\"arg1_premises\"]]),\n",
    "                pluralise_osherson_conclusion(row[\"arg1_conclusion\"]),\n",
    "            ),\n",
    "        )\n",
    "        for _, row in osherson_df.iterrows()\n",
    "    ]\n",
    ")\n",
    "\n",
    "included_categories = set(\n",
    "    domain_categories[\"Vehicles\"]\n",
    "    + domain_categories[\"Mammals\"]\n",
    "    + domain_categories[\"Birds\"]\n",
    ")\n",
    "nonmon_categories = set(\n",
    "    domain_categories[\"Insects\"]\n",
    "    + domain_categories[\"Reptiles\"]\n",
    "    + domain_categories[\"Tools\"]\n",
    ")\n",
    "\n",
    "\n",
    "def get_domain(premise: str, conclusion: str):\n",
    "    if \"All \" in conclusion:\n",
    "        return conclusion.replace(\"All \", \"\").capitalize()\n",
    "    else:\n",
    "        for domain, categories in domain_categories.items():\n",
    "            if conclusion in categories or premise in categories:\n",
    "                return domain\n",
    "    # is osherson\n",
    "    return \"Mammals\"\n",
    "\n",
    "\n",
    "def remove_participant_e1(df: pd.DataFrame):\n",
    "    controls = df[df[\"is_control\"]]\n",
    "    return len([x for x in controls[\"human_rating\"] if x > 2.5]) > 1\n",
    "\n",
    "\n",
    "def classify_pair(pair):\n",
    "    a1, a2 = pair\n",
    "    a1_p, a1_c = a1\n",
    "    a2_p, a2_c = a2\n",
    "\n",
    "    # Figure out general or specific\n",
    "    def conclusion_is_general(c):\n",
    "        return c in (\"All mammals\", \"All birds\", \"All vehicles\")\n",
    "\n",
    "    general = conclusion_is_general(a1_c) or conclusion_is_general(a2_c)\n",
    "\n",
    "    if pair in EXPERIMENT_1_CONTROLS:\n",
    "        return \"Similarity\"\n",
    "\n",
    "    # Special cases for osherson examples\n",
    "    if pair in (\n",
    "        (\n",
    "            ((\"Crows\", \"Peacocks\"), \"All birds\"),\n",
    "            ((\"Crows\", \"Peacocks\", \"Rabbits\"), \"All birds\"),\n",
    "        ),\n",
    "        (\n",
    "            ((\"Crows\", \"Peacocks\", \"Rabbits\"), \"All birds\"),\n",
    "            (\n",
    "                (\n",
    "                    \"Crows\",\n",
    "                    \"Peacocks\",\n",
    "                ),\n",
    "                \"All birds\",\n",
    "            ),\n",
    "        ),\n",
    "    ):\n",
    "        return \"Nonmonotonicity (General)\"\n",
    "    elif pair in (\n",
    "        (((\"Robins\", \"Bluejays\"), \"Geese\"), ((\"Robins\", \"Bluejays\"), \"Sparrows\")),\n",
    "        (((\"Robins\", \"Bluejays\"), \"Sparrows\"), ((\"Robins\", \"Bluejays\"), \"Geese\")),\n",
    "    ):\n",
    "        return \"Similarity\"\n",
    "\n",
    "    a1_p, a2_p = list(a1_p), list(a2_p)\n",
    "\n",
    "    # Specificity?\n",
    "    if \"things\" in a1_c or \"things\" in a2_c or \"animals\" in a1_c or \"animals\" in a2_c:\n",
    "        return \"Specificity\"\n",
    "\n",
    "    # nonmon?\n",
    "    for p in a1_p + a2_p:\n",
    "        if p in nonmon_categories:\n",
    "            return f\"Nonmonotonicity {'(Specific)' if not general else '(General)'}\"\n",
    "\n",
    "    # monotonicity?\n",
    "    if len(a1_p) != len(a2_p):\n",
    "        return f\"Monotonicity {'(Specific)' if not general else '(General)'}\"\n",
    "\n",
    "    # asymmetry/inclusion fallacy/similarity/typicality?\n",
    "    if len(a1_p) == 1 and len(a2_p) == 1:\n",
    "        if len(set(a1_p + a2_p + [a1_c, a2_c])) == 2:\n",
    "            return \"Asymmetry\"\n",
    "        elif (conclusion_is_general(a1_c) and not conclusion_is_general(a2_c)) or (\n",
    "            conclusion_is_general(a2_c) and not conclusion_is_general(a1_c)\n",
    "        ):\n",
    "            return \"Inclusion Fallacy\"\n",
    "        elif general:\n",
    "            return \"Typicality\"\n",
    "        else:\n",
    "            return \"Similarity\"\n",
    "\n",
    "    # Diversity\n",
    "    return f\"Diversity {'(Specific)' if not general else '(General)'}\"\n",
    "\n",
    "\n",
    "def arg2_is_stronger(pair, phenomenon_name, domain, is_osherson, is_control):\n",
    "    a1, a2 = pair\n",
    "    a1_p, a1_c = a1\n",
    "    a2_p, a2_c = a2\n",
    "\n",
    "    if not is_osherson and not is_control:\n",
    "        if phenomenon_name == \"Similarity\":\n",
    "            return (\n",
    "                similarity_map[domain][a1_p[0]][a1_c]\n",
    "                < similarity_map[domain][a2_p[0]][a2_c]\n",
    "            )\n",
    "        elif phenomenon_name == \"Typicality\":\n",
    "            return typicality_rank_map[domain].index(a1_p[0]) > typicality_rank_map[\n",
    "                domain\n",
    "            ].index(a2_p[0])\n",
    "        elif phenomenon_name == \"Specificity\":\n",
    "            return \"animal\" in a1_c or \"thing\" in a1_c\n",
    "        elif \"Monotonicity\" in phenomenon_name:\n",
    "            return len(a1_p) < len(a2_p)\n",
    "        elif \"Nonmonotonicity\" in phenomenon_name:\n",
    "            return len(a1_p) > len(a2_p)\n",
    "        elif \"Diversity\" in phenomenon_name:\n",
    "            return (\n",
    "                similarity_map[domain][a1_p[0]][a1_p[1]]\n",
    "                > similarity_map[domain][a2_p[0]][a2_p[1]]\n",
    "            )\n",
    "        elif phenomenon_name == \"Asymmetry\":\n",
    "            return typicality_rank_map[domain].index(a1_p[0]) > typicality_rank_map[\n",
    "                domain\n",
    "            ].index(a2_p[0])\n",
    "        elif phenomenon_name == \"Inclusion Fallacy\":\n",
    "            return a2_c not in included_categories\n",
    "    elif is_osherson:\n",
    "        p = ((\":\".join(a1_p), a1_c), (\":\".join(a2_p), a2_c))\n",
    "        return p in osherson_arg2_stronger\n",
    "    else:\n",
    "        p = (((a1_p[0],), a1_c), ((a2_p[0],), a2_c))\n",
    "        if p in EXPERIMENT_1_CONTROLS:\n",
    "            return EXPERIMENT_1_CONTROLS[p]\n",
    "        else:\n",
    "            return not EXPERIMENT_1_CONTROLS[(p[1], p[0])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "YlJ63o0rThfv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed participants: 10\n"
     ]
    }
   ],
   "source": [
    "human_e1 = pd.read_csv(f\"{RAW_DATA}/experiment_1_ratings.csv\")\n",
    "\n",
    "osherson_df[\"trial_args\"] = [\n",
    "    tuple(\n",
    "        sorted(\n",
    "            [\n",
    "                (\n",
    "                    \":\".join([ie.plural(p).capitalize() for p in row[\"arg1_premises\"]]),\n",
    "                    pluralise_osherson_conclusion(row[\"arg1_conclusion\"]),\n",
    "                ),\n",
    "                (\n",
    "                    \":\".join([ie.plural(p).capitalize() for p in row[\"arg2_premises\"]]),\n",
    "                    pluralise_osherson_conclusion(row[\"arg2_conclusion\"]),\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    for _, row in osherson_df.iterrows()\n",
    "]\n",
    "osherson_trials = set(osherson_df[\"trial_args\"])\n",
    "human_e1[\"trial_args\"] = [\n",
    "    tuple(\n",
    "        sorted(\n",
    "            [\n",
    "                (row[\"premises0\"], row[\"conclusion0\"]),\n",
    "                (row[\"premises1\"], row[\"conclusion1\"]),\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    for _, row in human_e1.iterrows()\n",
    "]\n",
    "\n",
    "human_e1[\"is_osherson\"] = human_e1[\"trial_args\"].apply(lambda x: x in osherson_trials)\n",
    "human_e1[\"human_rating\"] = human_e1[\"rating\"]\n",
    "human_e1[\"trialId_sort\"] = human_e1[\"trialId\"].apply(lambda x: int(x.replace(\"tc\", \"\")))\n",
    "human_e1 = human_e1.sort_values(by=[\"tid\", \"trialId_sort\"], ascending=True).reset_index(\n",
    "    drop=True\n",
    ")\n",
    "human_e1[\"premises0\"] = human_e1[\"premises0\"].apply(lambda x: x.split(\":\"))\n",
    "human_e1[\"premises1\"] = human_e1[\"premises1\"].apply(lambda x: x.split(\":\"))\n",
    "human_e1[\"conclusion0\"] = human_e1[\"conclusion0\"]\n",
    "human_e1[\"conclusion1\"] = human_e1[\"conclusion1\"]\n",
    "human_e1[\"is_control\"] = [\n",
    "    (\n",
    "        (tuple(row[\"premises0\"]), row[\"conclusion0\"]),\n",
    "        (tuple(row[\"premises1\"]), row[\"conclusion1\"]),\n",
    "    )\n",
    "    in EXPERIMENT_1_CONTROLS\n",
    "    or (\n",
    "        (tuple(row[\"premises1\"]), row[\"conclusion1\"]),\n",
    "        (tuple(row[\"premises0\"]), row[\"conclusion0\"]),\n",
    "    )\n",
    "    in EXPERIMENT_1_CONTROLS\n",
    "    for _, row in human_e1.iterrows()\n",
    "]\n",
    "human_e1[\"phenomenon\"] = [\n",
    "    classify_pair(\n",
    "        (\n",
    "            (tuple(row[\"premises0\"]), row[\"conclusion0\"]),\n",
    "            (tuple(row[\"premises1\"]), row[\"conclusion1\"]),\n",
    "        )\n",
    "    )\n",
    "    for _, row in human_e1.iterrows()\n",
    "]\n",
    "human_e1[\"domain\"] = [\n",
    "    get_domain(row[\"premises1\"][0], row[\"conclusion1\"])\n",
    "    for _, row in human_e1.iterrows()\n",
    "]\n",
    "human_e1[\"domain\"] = [\n",
    "    get_domain(row[\"premises0\"][0], row[\"conclusion0\"])\n",
    "    if row[\"domain\"] in (\"Animals\", \"Things\")\n",
    "    else row[\"domain\"]\n",
    "    for _, row in human_e1.iterrows()\n",
    "]\n",
    "human_e1[\"is_arg2_stronger\"] = [\n",
    "    arg2_is_stronger(\n",
    "        (\n",
    "            (row[\"premises0\"], row[\"conclusion0\"]),\n",
    "            (row[\"premises1\"], row[\"conclusion1\"]),\n",
    "        ),\n",
    "        row[\"phenomenon\"],\n",
    "        row[\"domain\"],\n",
    "        row[\"is_osherson\"],\n",
    "        row[\"is_control\"],\n",
    "    )\n",
    "    for _, row in human_e1.iterrows()\n",
    "]\n",
    "human_e1[\"phenomenon_type\"] = human_e1[\"phenomenon\"].map(lambda x: PHENOMENON_TYPE[x])\n",
    "\n",
    "human_e1[\"arg1_premises\"] = human_e1[\"premises0\"]\n",
    "human_e1[\"arg1_conclusion\"] = human_e1[\"conclusion0\"]\n",
    "human_e1[\"arg2_premises\"] = human_e1[\"premises1\"]\n",
    "human_e1[\"arg2_conclusion\"] = human_e1[\"conclusion1\"]\n",
    "human_e1[\"trial_id\"] = human_e1[\"trialId\"]\n",
    "\n",
    "# find participants who didn't pass the control trials\n",
    "remove_p = {}\n",
    "for uid, uid_df in human_e1.groupby(\"uid\"):\n",
    "    remove = remove_participant_e1(uid_df)\n",
    "    remove_p[uid] = remove\n",
    "human_e1[\"is_removed_participant\"] = human_e1[\"uid\"].apply(lambda x: remove_p[x])\n",
    "print(\n",
    "    f\"Number of removed participants: {len(human_e1[human_e1['is_removed_participant']]['uid'].unique())}\"\n",
    ")\n",
    "human_e1[\"argpair_id\"] = [\n",
    "    str(\n",
    "        row[\"arg1_premises\"]\n",
    "        + [row[\"arg1_conclusion\"]]\n",
    "        + row[\"arg2_premises\"]\n",
    "        + [row[\"arg2_conclusion\"]]\n",
    "    )\n",
    "    if not row[\"is_arg2_stronger\"]\n",
    "    else str(\n",
    "        row[\"arg2_premises\"]\n",
    "        + [row[\"arg2_conclusion\"]]\n",
    "        + row[\"arg1_premises\"]\n",
    "        + [row[\"arg1_conclusion\"]]\n",
    "    )\n",
    "    for _, row in human_e1.iterrows()\n",
    "]\n",
    "\n",
    "human_e1 = human_e1[\n",
    "    [\n",
    "        \"uid\",\n",
    "        \"tid\",\n",
    "        \"trial_id\",\n",
    "        \"argpair_id\",\n",
    "        \"phenomenon\",\n",
    "        \"phenomenon_type\",\n",
    "        \"domain\",\n",
    "        \"arg1_premises\",\n",
    "        \"arg1_conclusion\",\n",
    "        \"arg2_premises\",\n",
    "        \"arg2_conclusion\",\n",
    "        \"human_rating\",\n",
    "        \"is_arg2_stronger\",\n",
    "        \"is_control\",\n",
    "        \"is_osherson\",\n",
    "        \"is_removed_participant\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "assert all(\n",
    "    tdf.shape[0] == 10\n",
    "    for _, tdf in human_e1[~human_e1[\"is_control\"]].groupby([\"argpair_id\"])\n",
    ")\n",
    "assert all(\n",
    "    tdf.shape[0] == 120\n",
    "    for _, tdf in human_e1[human_e1[\"is_control\"]].groupby([\"argpair_id\"])\n",
    ")\n",
    "assert all(\n",
    "    tdf.shape[0] == 10\n",
    "    for _, tdf in human_e1[human_e1[\"is_osherson\"]].groupby([\"domain\", \"phenomenon\"])\n",
    ")\n",
    "assert all(\n",
    "    tdf.shape[0] == 240\n",
    "    for _, tdf in human_e1[~human_e1[\"is_control\"]].groupby([\"domain\", \"phenomenon\"])\n",
    ")\n",
    "\n",
    "human_e1.to_csv(f\"{PROCESSED_DATA}/experiment_1_master.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "bDu2WlnfUK-Y"
   },
   "outputs": [],
   "source": [
    "human_e1 = pd.read_csv(f\"{PROCESSED_DATA}/experiment_1_master.csv\", index_col=0)\n",
    "human_e1 = human_e1[~human_e1[\"is_removed_participant\"]].reset_index(drop=True)\n",
    "human_e1[\"arg1_premises\"] = human_e1[\"arg1_premises\"].apply(eval)\n",
    "human_e1[\"arg2_premises\"] = human_e1[\"arg2_premises\"].apply(eval)\n",
    "\n",
    "# Reorder e1 pairs so that stronger pair is always arg1\n",
    "arg1_premises, arg1_conclusion, arg2_premises, arg2_conclusion, human_rating = (\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    ")\n",
    "for _, row in human_e1.iterrows():\n",
    "    if row[\"is_arg2_stronger\"]:\n",
    "        arg1_premises.append(row[\"arg2_premises\"])\n",
    "        arg1_conclusion.append(row[\"arg2_conclusion\"])\n",
    "        arg2_premises.append(row[\"arg1_premises\"])\n",
    "        arg2_conclusion.append(row[\"arg1_conclusion\"])\n",
    "        human_rating.append(5 - row[\"human_rating\"])\n",
    "    else:\n",
    "        arg1_premises.append(row[\"arg1_premises\"])\n",
    "        arg1_conclusion.append(row[\"arg1_conclusion\"])\n",
    "        arg2_premises.append(row[\"arg2_premises\"])\n",
    "        arg2_conclusion.append(row[\"arg2_conclusion\"])\n",
    "        human_rating.append(row[\"human_rating\"])\n",
    "(\n",
    "    human_e1[\"arg1_premises\"],\n",
    "    human_e1[\"arg1_conclusion\"],\n",
    "    human_e1[\"arg2_premises\"],\n",
    "    human_e1[\"arg2_conclusion\"],\n",
    "    human_e1[\"human_rating\"],\n",
    ") = (arg1_premises, arg1_conclusion, arg2_premises, arg2_conclusion, human_rating)\n",
    "human_e1[\"is_arg2_stronger\"] = [False] * human_e1.shape[0]\n",
    "\n",
    "# Aggregate e1 argument pairs\n",
    "rows = []\n",
    "for a, adf in human_e1.groupby(\n",
    "    [\"argpair_id\", \"phenomenon\", \"phenomenon_type\", \"domain\"]\n",
    "):\n",
    "    argpair_id, phenomenon, phenomeonon_type, domain = a\n",
    "    first_row = adf.iloc[0]\n",
    "    rows.append(\n",
    "        (\n",
    "            argpair_id,\n",
    "            phenomenon,\n",
    "            phenomeonon_type,\n",
    "            domain,\n",
    "            first_row[\"arg1_premises\"],\n",
    "            first_row[\"arg1_conclusion\"],\n",
    "            first_row[\"arg2_premises\"],\n",
    "            first_row[\"arg2_conclusion\"],\n",
    "            np.mean(adf[\"human_rating\"]),\n",
    "            first_row[\"is_control\"],\n",
    "            first_row[\"is_osherson\"],\n",
    "        )\n",
    "    )\n",
    "aggregated_e1 = pd.DataFrame(\n",
    "    rows,\n",
    "    columns=[\n",
    "        \"argpair_id\",\n",
    "        \"phenomenon\",\n",
    "        \"phenomenon_type\",\n",
    "        \"domain\",\n",
    "        \"stronger_arg_premises\",\n",
    "        \"stronger_arg_conclusion\",\n",
    "        \"weaker_arg_premises\",\n",
    "        \"weaker_arg_conclusion\",\n",
    "        \"average_human_rating\",\n",
    "        \"is_control\",\n",
    "        \"is_osherson\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Add SCM scores\n",
    "scmable_phenomena = set(\n",
    "    [\n",
    "        \"Similarity\",\n",
    "        \"Typicality\",\n",
    "        \"Monotonicity (General)\",\n",
    "        \"Monotonicity (Specific)\",\n",
    "        \"Diversity (General)\",\n",
    "        \"Diversity (Specific)\",\n",
    "        \"Asymmetry\",\n",
    "        \"Inclusion Fallacy\",\n",
    "    ]\n",
    ")\n",
    "strong_scm_scores, weak_scm_scores = [], []\n",
    "for _, row in aggregated_e1.iterrows():\n",
    "    if (\n",
    "        row[\"is_osherson\"]\n",
    "        or row[\"is_control\"]\n",
    "        or row[\"phenomenon\"] not in scmable_phenomena\n",
    "    ):\n",
    "        strong_scm_scores.append(None)\n",
    "        weak_scm_scores.append(None)\n",
    "    else:\n",
    "        a1_p, a1_c, a2_p, a2_c = (\n",
    "            row[\"stronger_arg_premises\"],\n",
    "            row[\"stronger_arg_conclusion\"],\n",
    "            row[\"weaker_arg_premises\"],\n",
    "            row[\"weaker_arg_conclusion\"],\n",
    "        )\n",
    "        strong_scm_scores.append(\n",
    "            scm(\n",
    "                a1_p,\n",
    "                a1_c,\n",
    "                domain_categories[row[\"domain\"]],\n",
    "                similarity_map[row[\"domain\"]],\n",
    "                row[\"phenomenon_type\"] == \"Specific\",\n",
    "            )\n",
    "        )\n",
    "        weak_scm_scores.append(\n",
    "            scm(\n",
    "                a2_p,\n",
    "                a2_c,\n",
    "                domain_categories[row[\"domain\"]],\n",
    "                similarity_map[row[\"domain\"]],\n",
    "                row[\"phenomenon_type\"] == \"Specific\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "aggregated_e1[\"stronger_arg_scm\"] = strong_scm_scores\n",
    "aggregated_e1[\"weaker_arg_scm\"] = weak_scm_scores\n",
    "\n",
    "# Add in original osherson ratings\n",
    "OSHERSON_E1_RATINGS = {\n",
    "    \"Typicality\": 73 / 80,\n",
    "    \"Diversity (General)\": 59 / 80,\n",
    "    \"Specificity\": 75 / 80,\n",
    "    \"Monotonicity (General)\": 75 / 80,\n",
    "    \"Similarity\": 76 / 80,\n",
    "    \"Diversity (Specific)\": 52 / 80,\n",
    "    \"Monotonicity (Specific)\": 66 / 80,\n",
    "    \"Asymmetry\": 40 / 80,\n",
    "    \"Nonmonotonicity (General)\": 68 / 80,\n",
    "    \"Inclusion Fallacy\": 52 / 80,\n",
    "}\n",
    "aggregated_e1[\"osherson_rating\"] = [\n",
    "    OSHERSON_E1_RATINGS[row[\"phenomenon\"]] if row[\"is_osherson\"] else None\n",
    "    for _, row in aggregated_e1.iterrows()\n",
    "]\n",
    "aggregated_e1[\"conclusion_type\"] = aggregated_e1[\"phenomenon_type\"]\n",
    "\n",
    "aggregated_e1 = aggregated_e1[\n",
    "    [\n",
    "        \"argpair_id\",\n",
    "        \"phenomenon\",\n",
    "        \"conclusion_type\",\n",
    "        \"domain\",\n",
    "        \"stronger_arg_premises\",\n",
    "        \"stronger_arg_conclusion\",\n",
    "        \"weaker_arg_premises\",\n",
    "        \"weaker_arg_conclusion\",\n",
    "        \"average_human_rating\",\n",
    "        \"osherson_rating\",\n",
    "        \"stronger_arg_scm\",\n",
    "        \"weaker_arg_scm\",\n",
    "        \"is_control\",\n",
    "        \"is_osherson\",\n",
    "    ]\n",
    "]\n",
    "aggregated_e1.to_csv(f\"{PROCESSED_DATA}/experiment_1_aggregated.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_9h4agZvURyN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
